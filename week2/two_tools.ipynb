{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50e9684c-f612-45e4-9f26-daf6cd6c1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "import base64\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66410190-fe99-485a-b3f9-d39e471fb91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a47211-8e2a-48bd-ac82-dd8ab8fb9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt='You are an helpful assistant'\n",
    "system_prompt+='You work at an airline called FLYYO'\n",
    "system_prompt+='You always do everything in your best effort to help out customers'\n",
    "system_prompt+='Incase they ask anything you dont know tell them you dont know'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6648f99d-5dff-4c7b-8cb8-2cc8e498f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\", \"kampala\":\"$450\"}\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price for {destination_city} called\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91cf52a-e89b-4e39-afbe-8ba5a94244ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price for kampala called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$450'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price('kampala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e26299-b891-4e4d-a0ce-15d0c3b42bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "# This makes it easy for openai to understand your tools/functions.\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e34b251f-e2ec-4a77-8127-f5c4cb0a4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_times = {'morning':'Boeing 737', 'afternoon':'Airbus A320 family', 'Evening':'Boeing 777', 'night':'Global 8000'}\n",
    "\n",
    "def avv_plane(a_time):\n",
    "    print(f\"Tool showing available plane in the {a_time} called\")\n",
    "    return plane_times.get(a_time.lower(), 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e1fde95-98e1-40f2-ada3-b1d0fdb0d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool showing available plane in the morning called\n",
      "Boeing 737\n"
     ]
    }
   ],
   "source": [
    "print(avv_plane('morning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18f0029-f7a0-473f-9bba-f9292b576f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_function = {\n",
    "    'name':'avv_plane',\n",
    "    'description':'Get the plane availabe at the time the customer wants to travel, Call this whenever you want to know the available plane in the time the user wants to travel.for example the customer asks \"Which aeroplane/plane will be there in the morning\"',\n",
    "    'parameters':{\n",
    "        'type':'object',\n",
    "        'properties':{\n",
    "            'a_time':{\n",
    "                'type':'string',\n",
    "                'description':'the time at which the customer wants to travel'\n",
    "            }\n",
    "        },\n",
    "        'required':['a_time'],\n",
    "        'additionalProperties':False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec063b32-d834-4f46-b5bc-18eb09409576",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{'type':'function', 'function':price_function} , {'type':'function', 'function':plane_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e297f2c-6219-4230-9e3d-f6f0db768ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price for Kampala called\n"
     ]
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{'role':'system', 'content':system_prompt}] + history + [{'role':'user', 'content':message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason=='tool_calls':\n",
    "        message = response.choices[0].message\n",
    "        tool_response = handle_tool_call(message) # This handles what is returned by the tool call.\n",
    "        messages.append(message)\n",
    "        messages.append(tool_response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn = chat, type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7971d444-ae36-4cd0-b44e-ac6cb2fe78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple way to handle multiple tool calls using a for loop.\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    for tool_call in message.tool_calls: # Looks for a given tool in message.tool_calls\n",
    "        if tool_call.function.name == 'get_ticket_price': # In this case, this only runs if the tool called is get_ticket_price'\n",
    "            arguments = json.loads(tool_call.function.arguments) # The name used for tool calls is the one used in the tool's function.\n",
    "            city = arguments.get('destination_city')\n",
    "            price = get_ticket_price(city)\n",
    "            return {\n",
    "                \"role\": \"tool\",       # Incase the tool call is successful, it will return this dict as the tool response.\n",
    "                \"content\": f\"The ticket price to {city} is ${price}\", \n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"city\":city  # Passed in the city key and value so that we are able to capture it.\n",
    "            }\n",
    "            return None\n",
    "        if tool_call.function.name == 'avv_plane':\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            a_time = arguments.get('a_time')\n",
    "            plane = avv_plane(a_time)\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": f\"Available planes at {a_time}: {plane}\",\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            }\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fccbcb2-71e6-4a2e-a73e-8290f25ce6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response=openai.images.generate(\n",
    "        model='dall-e-3',\n",
    "        prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "        size='1024x1024',\n",
    "        n=1,\n",
    "        response_format=\"b64_json\"\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa87e51c-b9f0-492d-bf97-b7fbe7b8cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    custom_temp_dir = os.path.expanduser(\"~/Documents/temp_audio\")\n",
    "    os.environ['TEMP'] = custom_temp_dir\n",
    "    \n",
    "    if not os.path.exists(custom_temp_dir):\n",
    "        os.makedirs(custom_temp_dir)\n",
    "    \n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed300978-ced0-4604-a85b-8fa760e1cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "\n",
    "    if response.choices[0].finish_reason=='tool_calls':\n",
    "        message = response.choices[0].message\n",
    "        tool_response = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(tool_response)\n",
    "        image = artist(tool_response['city'])\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    talker(reply)\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "569e9e56-3f44-4beb-9f2c-96326898a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file):\n",
    "    \"\"\"Convert audio to text using OpenAI Whisper\"\"\"\n",
    "    if audio_file is None or not os.path.isfile(audio_file):\n",
    "        print(f\"[Error] Invalid file path: {audio_file}\")\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Open the audio file and transcribe it\n",
    "        with open(audio_file, \"rb\") as audio:\n",
    "            transcript = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio,\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        return transcript.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Transcription error: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c57c80d1-3a6a-4948-81e5-5c7445640ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_input(audio_file, history):\n",
    "    \"\"\"Process audio input: transcribe, then chat\"\"\"\n",
    "    if audio_file is None:\n",
    "        return \"\", history, None\n",
    "        \n",
    "    transcribed_text = transcribe_audio(audio_file)\n",
    "    \n",
    "    if not transcribed_text:\n",
    "        return \"\", history, None\n",
    "    \n",
    "    # Add user message to history\n",
    "    history = history or []\n",
    "    history.append({\"role\": \"user\", \"content\": transcribed_text})\n",
    "    \n",
    "    # Process through existing chat system\n",
    "    updated_history, image = chat(history)\n",
    "    \n",
    "    # Return empty audio (to clear the input), updated history, and image\n",
    "    return None, updated_history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94759386-5039-46d3-8bdf-6e081d01c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_entry(message, history):\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "        \n",
    "    history = history or []\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    return \"\", history\n",
    "\n",
    "# NEW: Process text input through chat\n",
    "def process_text_input(message, history):\n",
    "    \"\"\"Handle text input and process through chat\"\"\"\n",
    "    if not message.strip():\n",
    "        return \"\", history, None\n",
    "    \n",
    "    # Add to history\n",
    "    history = history or []\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # Process through chat\n",
    "    updated_history, image = chat(history)\n",
    "    \n",
    "    return \"\", updated_history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f67a81d-5d5c-4959-bff8-1eca85151578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2157, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1947, in postprocess_data\n",
      "    await processing_utils.async_move_files_to_cache(\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 648, in async_move_files_to_cache\n",
      "    return await client_utils.async_traverse(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio_client\\utils.py\", line 1129, in async_traverse\n",
      "    return await func(json_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 621, in _move_to_cache\n",
      "    temp_file_path = await block.async_move_resource_to_block_cache(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 316, in async_move_resource_to_block_cache\n",
      "    temp_file_path = processing_utils.save_file_to_cache(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 277, in save_file_to_cache\n",
      "    temp_dir = hash_file(file_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 206, in hash_file\n",
      "    with open(file_path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\OFFICIAL\\\\LLM_Course_Donner\\\\llm_engineering\\\\week2'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2157, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1947, in postprocess_data\n",
      "    await processing_utils.async_move_files_to_cache(\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 648, in async_move_files_to_cache\n",
      "    return await client_utils.async_traverse(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio_client\\utils.py\", line 1129, in async_traverse\n",
      "    return await func(json_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 621, in _move_to_cache\n",
      "    temp_file_path = await block.async_move_resource_to_block_cache(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 316, in async_move_resource_to_block_cache\n",
      "    temp_file_path = processing_utils.save_file_to_cache(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 277, in save_file_to_cache\n",
      "    temp_dir = hash_file(file_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\OFFICIAL\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\processing_utils.py\", line 206, in hash_file\n",
      "    with open(file_path, \"rb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\OFFICIAL\\\\LLM_Course_Donner\\\\llm_engineering\\\\week2'\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    \n",
    "    with gr.Row():\n",
    "        # Text input\n",
    "        entry = gr.Textbox(label=\"Type your message:\", placeholder=\"Type here or use voice input below...\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        # Audio input\n",
    "        audio_input = gr.Audio(\n",
    "            sources=[\"microphone\"],\n",
    "            type=\"filepath\",\n",
    "            show_label=False,\n",
    "            scale=3\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear Chat\")\n",
    "    \n",
    "    # Text input handling\n",
    "    entry.submit(\n",
    "        process_text_input,\n",
    "        inputs=[entry, chatbot],\n",
    "        outputs=[entry, chatbot, image_output]\n",
    "    )\n",
    "    \n",
    "    # Audio input handling\n",
    "    audio_input.change(\n",
    "        process_audio_input,\n",
    "        inputs=[audio_input, chatbot],\n",
    "        outputs=[audio_input, chatbot, image_output]\n",
    "    )\n",
    "    \n",
    "    # Clear chat\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb2d43c9-9e55-4153-a636-ebe2d906413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.47.1.windows.1\n"
     ]
    }
   ],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cc53d7d-174c-448f-92ba-aee8f47c415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   ../extras/community/prototype_signal.ipynb\n",
      "\tmodified:   ../extras/trading/prototype_trader.ipynb\n",
      "\tmodified:   ../week1/Guide to Jupyter.ipynb\n",
      "\tmodified:   ../week1/Intermediate Python.ipynb\n",
      "\tmodified:   ../week1/day1.ipynb\n",
      "\tmodified:   ../week1/day2 EXERCISE.ipynb\n",
      "\tmodified:   ../week1/day5.ipynb\n",
      "\tmodified:   ../week1/troubleshooting.ipynb\n",
      "\tmodified:   ../week1/week1 EXERCISE.ipynb\n",
      "\tmodified:   day1.ipynb\n",
      "\tmodified:   day2.ipynb\n",
      "\tmodified:   day3.ipynb\n",
      "\tmodified:   day4.ipynb\n",
      "\tmodified:   day5.ipynb\n",
      "\tmodified:   week2 EXERCISE.ipynb\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t../.env.txt\n",
      "\t../PesaPal_Documentation.txt\n",
      "\tbro_lingo.ipynb\n",
      "\tcompany_brochure.ipynb\n",
      "\toutput_audio.mp3\n",
      "\trequirements.txt\n",
      "\ttwo_tools.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a783fc02-8913-496c-8af8-760718eab0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'week2/two_tools.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add two_tools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e90241b6-f793-4113-ae63-6e1b2c17ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3e988bc] Heyy, its about the two tools simplifed method using a for loop\n",
      " 1 file changed, 649 insertions(+)\n",
      " create mode 100644 week2/two_tools.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Heyy, its about the two tools simplifed method using a for loop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01c971d3-2a1d-4284-bce3-d32749dbccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/aaron-official/llm_engineering.git\n",
      " ! [rejected]        main -> main (fetch first)\n",
      "error: failed to push some refs to 'https://github.com/aaron-official/llm_engineering.git'\n",
      "hint: Updates were rejected because the remote contains work that you do not\n",
      "hint: have locally. This is usually caused by another repository pushing to\n",
      "hint: the same ref. If you want to integrate the remote changes, use\n",
      "hint: 'git pull' before pushing again.\n",
      "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f972ac1-47f1-4a72-b03e-41c6f014b56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
