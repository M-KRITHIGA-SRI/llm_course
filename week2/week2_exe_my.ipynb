{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853fe71-802e-4b81-a3eb-cbe8e2d91562",
   "metadata": {},
   "source": [
    "## My Tutor text board\n",
    "* ask gpt-40-mini a python math problem, then use my tool to do that  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "389f3cfd-e19c-4ea1-a2bd-650d342ac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "# import ollama\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17b3c0fb-bd25-4d3d-b404-e4427512605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL = 'gpt-4o-mini'\n",
    "# MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a35abb62-4fb4-42bf-b3ef-271c44981e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1fbb084-078b-453a-aba2-41b213b3164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful technical assistant. If asked of online course prices, then provide.  \"\n",
    "system_message += \"Give concise and informative answers, try no more than 5 sentences. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f455913c-d06d-4429-af34-45d5cf62b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "course_price = {\"ai\": \"$119\", \"python\": \"$49\", \"machine learning\": \"$99\", \"llm\": \"$199\"}\n",
    "\n",
    "def get_course_price(online_course):\n",
    "    print(f\"-> Tool: get_course_price is called for course => {online_course}\\n\")\n",
    "    course = online_course.lower()\n",
    "    return course_price.get(course, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34c71ebd-b1db-48f3-ae6c-599a2a9386b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Tool: get_course_price is called for course => LLM\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$199'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_course_price(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "714cf419-9e97-41b8-85d2-4393ef950f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_course_price\",\n",
    "    \"description\": \"Get the price of the price for an online course. Call this whenever you need to know the course price, for example when a customer asks 'How much is the course for LLM'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"online_course\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The online course that the customer wants to take\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"online_course\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "014c57ea-02bd-400a-bb59-22922ed9a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d45438b4-3c2d-44d1-8d35-c6b8ac185c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    # print(\"response ->\", response, \"\\n\")\n",
    "\n",
    "    # The description and parameters you provide act like an internal “map” that helps \n",
    "    # the model match intent to function.\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":  # it's the assistant making the tool call\n",
    "        message = response.choices[0].message\n",
    "        # print(\"message ->\", message, \"\\n\")\n",
    "        \n",
    "        response, course = handle_tool_call(message)\n",
    "        # print(\"response -> \", response , \"\\n\", course, \"\\n\")\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a2d5b19f-4b7e-4f1b-bbff-0219ec3abb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    course = arguments.get('online_course')\n",
    "    price = get_course_price(course)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"online_course\": course,\"price\": price}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5dce8-3910-4b27-bd4c-b51964256b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b2e20-6b69-4ce7-ba75-0b81eb203a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a806e-080d-4307-8915-f7230c47528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af877f93-d580-4896-97b9-544346ab1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "# question = \"\"\"\n",
    "# Please explain what this code does and why:\n",
    "# yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "# \"\"\"\n",
    "# question = 'how does AI tool cursor work, be super brief please?'\n",
    "# question = 'how does git work, please be super brief? please translate to chinese.'\n",
    "\n",
    "# question = input(\"Enter your question: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bff01a-03c2-4b69-bd89-f7cc2debc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function looks rather simpler than the one from my video, because we're taking advantage of the latest Gradio updates\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09690154-2339-422c-ba6d-6dd6522bef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "\n",
    "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd159c41-d38b-4583-83e7-a227855a0910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please give a detailed explanation to the following question: how does AI tool cursor work, be super brief please?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067531e5-8374-412b-9aaf-7c3cde6308b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4584ae29-0fe1-4280-8b11-de73773897aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The AI tool \"Cursor\" works primarily as an integrated development environment (IDE) enhanced by artificial intelligence capabilities. It assists developers by providing features such as code suggestions, autocomplete, error detection, and real-time documentation. \n",
       "\n",
       "Here's a brief breakdown of its operation:\n",
       "\n",
       "1. **Context Awareness**: Cursor analyzes the context of the code being worked on, including the current file, libraries in use, and coding patterns.\n",
       "\n",
       "2. **AI Models**: It employs natural language processing and machine learning models trained on extensive codebases to understand coding syntax and semantics.\n",
       "\n",
       "3. **Code Suggestions**: As developers write code, Cursor predicts and suggests completions or corrections based on the learned patterns.\n",
       "\n",
       "4. **Integration**: The tool integrates with popular coding platforms and languages, allowing seamless use within the developer's workflow.\n",
       "\n",
       "5. **Learning and Adaptation**: Cursor may refine its suggestions as it learns from the user's coding style and preferences over time.\n",
       "\n",
       "Overall, Cursor aims to enhance productivity by making coding faster and more intuitive."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, w/o streaming\n",
    "def tutor():\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ]\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))\n",
    "    \n",
    "tutor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0675b28-52d7-42c0-be28-b5180ec258e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
