{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c7a35-39ff-4d73-8805-cdaecbe5c2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3767e529-e3f2-4a8f-8012-9c4aa62bbbb9",
   "metadata": {},
   "source": [
    "You're very welcome! üòä\n",
    "\n",
    "You're doing an awesome job exploring how to build practical AI tools ‚Äî keep going! Whether it's for voice, text, financial analysis, or agent design, I'm here to help with:\n",
    "\n",
    "* ‚úÖ Code examples\n",
    "* ‚úÖ Architecture advice\n",
    "* ‚úÖ Learning resources\n",
    "* ‚úÖ Debugging help\n",
    "* ‚úÖ AI agent ideas\n",
    "\n",
    "Whenever you're ready to take the next step (e.g., voice ‚Üí cleaned English ‚Üí saved to file or sent to Google Docs), just let me know.\n",
    "\n",
    "Happy building! üõ†Ô∏è‚ú®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3149b0-fe66-4c5f-9992-f2de9d0e463b",
   "metadata": {},
   "source": [
    "You're welcome! üôå\n",
    "\n",
    "**No, this version does *not* use the OpenAI API.**\n",
    "It is 100% **free and local**, using only open-source libraries:\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ What It Uses:\n",
    "\n",
    "| Feature        | Tool      | Cost | Notes                            |\n",
    "| -------------- | --------- | ---- | -------------------------------- |\n",
    "| Text-to-speech | `pyttsx3` | Free | Works offline on Mac, no API key |\n",
    "| Web UI         | `gradio`  | Free | Local browser-based interface    |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ What It Doesn't Use:\n",
    "\n",
    "* ‚ùå No OpenAI API (no API key or cost)\n",
    "* ‚ùå No internet access required after installing packages\n",
    "* ‚ùå No paid services or subscriptions\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ How It Works:\n",
    "\n",
    "`pyttsx3` uses your Mac's built-in **macOS voice engine** (`NSSpeechSynthesizer` under the hood), which means:\n",
    "\n",
    "* You get **Siri-quality voices**\n",
    "* You can switch to different accents/voices available on your Mac\n",
    "* It works even **offline**\n",
    "\n",
    "---\n",
    "\n",
    "If later you want to use **OpenAI for better voice generation** (like ultra-realistic voices), we *can* upgrade to use their TTS API ‚Äî but that would involve cost. For now, this is perfect for practice and use cases like:\n",
    "\n",
    "* Proofreading your own writing by listening\n",
    "* Practicing English comprehension\n",
    "* Reading long-form content aloud (articles, essays, etc.)\n",
    "\n",
    "Let me know if you want a **reverse version next** (voice ‚Üí text ‚Üí cleaned English), or want to export to file/Google Docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a5906a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"say 'Hello from Mac terminal'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d47da7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "print(f\"Available voices: {[voice.name for voice in voices]}\")\n",
    "\n",
    "engine.say(\"Hello from your Mac\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb0256a-896a-4a66-b8f3-e7659536c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d79c0b-0995-4a6d-9aba-300c82842c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7884\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Install the dependencies before running this script:\n",
    "# pip install gradio pyttsx3\n",
    "\n",
    "# import gradio as gr\n",
    "# import pyttsx3\n",
    "\n",
    "# Initialize TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Optional: customize voice properties (rate, volume)\n",
    "engine.setProperty('rate', 150)      # speed (default ~200)\n",
    "engine.setProperty('volume', 1.0)    # 0.0 to 1.0\n",
    "\n",
    "# Get available voices (for Mac, use 'com.apple.speech.synthesis.voice.samantha' or similar)\n",
    "voices = engine.getProperty('voices')\n",
    "voice_names = [v.name for v in voices]\n",
    "voice_id_map = {v.name: v.id for v in voices}\n",
    "\n",
    "# Function that converts text to speech\n",
    "def read_text(text, voice_choice):\n",
    "    engine.setProperty('voice', voice_id_map[voice_choice])\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    return f\"‚úÖ Done reading {len(text)} characters.\"\n",
    "\n",
    "# Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=read_text,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=10, label=\"Enter text to read aloud\"),\n",
    "        gr.Dropdown(choices=voice_names, label=\"Choose voice\", value=voice_names[0]),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"üó£Ô∏è Text-to-Speech Agent (Offline & Free)\",\n",
    "    description=\"Paste any text and click to read it aloud using your Mac's voice engine.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3318a-780a-4df0-847b-fcd1cd3230b8",
   "metadata": {},
   "source": [
    "Absolutely! Here's a **complete, free, offline-friendly voice-to-text agent** you can run on your **MacBook**. It will:\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What This Agent Does (Voice ‚Üí Text)\n",
    "\n",
    "1. **Record your voice** using your mic\n",
    "2. **Transcribe it into text** using **OpenAI Whisper (via `whisper` or `faster-whisper`)**\n",
    "3. **Display it in a simple Gradio web UI**\n",
    "4. **Optionally save it to a `.txt` file**\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Tools Used\n",
    "\n",
    "| Tool                               | Purpose                    | Free? | Notes                               |\n",
    "| ---------------------------------- | -------------------------- | ----- | ----------------------------------- |\n",
    "| `gradio`                           | UI for file upload or mic  | ‚úÖ     | Runs locally                        |\n",
    "| `whisper`                          | Voice-to-text (ASR) engine | ‚úÖ     | Local transcription (no API needed) |\n",
    "| `sounddevice` + `scipy.io.wavfile` | Record audio               | ‚úÖ     | Optional, if you want live mic      |\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Install Dependencies (One-Time Setup)\n",
    "\n",
    "```bash\n",
    "pip install gradio openai-whisper sounddevice scipy\n",
    "```\n",
    "\n",
    "> üí° On Mac, you may also need `ffmpeg`. Install it with:\n",
    "\n",
    "```bash\n",
    "brew install ffmpeg\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† End-to-End Code: `voice_to_text_agent.py`\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "import whisper\n",
    "import tempfile\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Load Whisper model once (base is good for most use cases; can change to 'small', 'medium', etc.)\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Optional: live mic recording\n",
    "def record_audio(duration=5, samplerate=16000):\n",
    "    gr.Info(f\"Recording for {duration} seconds...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    write(temp_file.name, samplerate, recording)\n",
    "    return temp_file.name\n",
    "\n",
    "# Transcribe uploaded or recorded audio\n",
    "def transcribe_audio(audio_path):\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Combined function for Gradio interface\n",
    "def transcribe_from_input(audio_file, record_duration):\n",
    "    if audio_file is not None:\n",
    "        audio_path = audio_file\n",
    "    else:\n",
    "        audio_path = record_audio(duration=record_duration)\n",
    "    \n",
    "    transcript = transcribe_audio(audio_path)\n",
    "    os.remove(audio_path)  # clean up temp file\n",
    "    return transcript\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe_from_input,\n",
    "    inputs=[\n",
    "        gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload audio (optional)\"),\n",
    "        gr.Slider(minimum=2, maximum=10, value=5, step=1, label=\"Record duration (seconds)\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"üéôÔ∏è Voice to Text Agent (Offline Whisper)\",\n",
    "    description=\"Record or upload audio and transcribe it using Whisper, offline and free.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è How to Use It\n",
    "\n",
    "1. **Run the script:**\n",
    "\n",
    "   ```bash\n",
    "   python voice_to_text_agent.py\n",
    "   ```\n",
    "\n",
    "2. **In the browser UI:**\n",
    "\n",
    "   * Either upload an audio file (`.wav`, `.mp3`)\n",
    "   * Or click ‚ÄúSubmit‚Äù to record your voice live (5 seconds by default)\n",
    "\n",
    "3. ‚úÖ You'll see your voice converted to text!\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Optional Enhancements\n",
    "\n",
    "* Save the transcript to a `.txt` or `.docx` file\n",
    "* Clean up informal grammar (integrate with GPT)\n",
    "* Add language selection\n",
    "* Combine with previous agent (voice ‚Üí clean English ‚Üí read aloud)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùìWant the next version?\n",
    "\n",
    "If you'd like:\n",
    "\n",
    "* Reverse pipeline: Voice ‚Üí Cleaned English ‚Üí Google Doc\n",
    "* A mobile-friendly version\n",
    "* Whisper running faster (using `faster-whisper` with GPU)\n",
    "\n",
    "Just say the word and I‚Äôll build that too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3cdafc-6ce8-4816-b02c-85b27874d748",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwhisper\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtempfile\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'whisper'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "import tempfile\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329bb2b-ce5d-44f1-9c23-badbecf56968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "import tempfile\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Load Whisper model once (base is good for most use cases; can change to 'small', 'medium', etc.)\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Optional: live mic recording\n",
    "def record_audio(duration=5, samplerate=16000):\n",
    "    gr.Info(f\"Recording for {duration} seconds...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    write(temp_file.name, samplerate, recording)\n",
    "    return temp_file.name\n",
    "\n",
    "# Transcribe uploaded or recorded audio\n",
    "def transcribe_audio(audio_path):\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Combined function for Gradio interface\n",
    "def transcribe_from_input(audio_file, record_duration):\n",
    "    if audio_file is not None:\n",
    "        audio_path = audio_file\n",
    "    else:\n",
    "        audio_path = record_audio(duration=record_duration)\n",
    "    \n",
    "    transcript = transcribe_audio(audio_path)\n",
    "    os.remove(audio_path)  # clean up temp file\n",
    "    return transcript\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe_from_input,\n",
    "    inputs=[\n",
    "        gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload audio (optional)\"),\n",
    "        gr.Slider(minimum=2, maximum=10, value=5, step=1, label=\"Record duration (seconds)\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"üéôÔ∏è Voice to Text Agent (Offline Whisper)\",\n",
    "    description=\"Record or upload audio and transcribe it using Whisper, offline and free.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00175a-49b9-46ce-a160-f1b7fd42f7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49916c2f-09c1-482c-aa82-163c249fc273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8666efc-1516-40e8-bad2-5db1d198ee95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "# call 2 tools\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853fe71-802e-4b81-a3eb-cbe8e2d91562",
   "metadata": {},
   "source": [
    "## My Tutor text board\n",
    "* ask gpt-40-mini a python math problem, then use my tool to do that  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389f3cfd-e19c-4ea1-a2bd-650d342ac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI  # import as class?\n",
    "# import ollama\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93d26152-679f-45a1-aaf2-19c39b557d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78.1\n",
      "Full Response Tree:\n",
      "{\n",
      "  \"id\": \"chatcmpl-BYENZQlkQVuEOP5UFSZ8TgEOJu9IO\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1747498125,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_0392822090\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 363,\n",
      "    \"total_tokens\": 373,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Message Tree:\n",
      "{\n",
      "  \"content\": \"Hello! How can I assist you today?\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"annotations\": [],\n",
      "  \"audio\": null,\n",
      "  \"function_call\": null,\n",
      "  \"tool_calls\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai  # import module\n",
    "print(openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b3c0fb-bd25-4d3d-b404-e4427512605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL = 'gpt-4o-mini'\n",
    "# MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35abb62-4fb4-42bf-b3ef-271c44981e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fbb084-078b-453a-aba2-41b213b3164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_message = (\n",
    "    \"You are a helpful assistant with access to two tools: \"\n",
    "    \"1) 'count_letter_in_word' - to count how many times a letter appears in a word or the sentance. \"\n",
    "    \"Use this when the user asks questions like 'How many R's are in Strawberry?', or \" \n",
    "    \"'how many E's are in this sentence?'. \"\n",
    "    \"2) 'get_online_course_price' - to retrieve prices for online courses. \"\n",
    "    \"Use this when the user asks about course prices like 'What is the price of AI Ethics course?'. \"\n",
    "    \"Always pick the tool that best fits the user's question.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005450f-1d5a-4aee-8a9c-acac5fbd65b6",
   "metadata": {},
   "source": [
    "## Defined 2 tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e213a7f2-1013-401d-9798-33c81520451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Tool: count_letter_in_word is called for counting letter in a word  => (\"how many a's in this sentance?\", 'A')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "def count_letter_in_word(word, letter):\n",
    "    print(f\"-> Tool: count_letter_in_word is called for counting letter in a word  => {word, letter}\\n\")\n",
    "    counter = 0\n",
    "\n",
    "    for c in word.lower():\n",
    "        if c == letter.lower():\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "count_letter_in_word(\"how many a's in this sentance?\", \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526500a4-35c7-44f2-8c37-e206acb4cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "# has 2 parameters\n",
    "\n",
    "count_function = {\n",
    "    \"name\": \"count_letter_in_word\",\n",
    "    \"description\": \n",
    "        \"Count the number of a given letter in a specific word. \"\n",
    "        \"Call this tool when the user asks questions like: \"\n",
    "        \"'How many R's are in the word Strawberry?', \"\n",
    "        \"'Count the letter A in banana', or \"\n",
    "        \"'Number of T's in cat'.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"word\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The word in which to count letters\",\n",
    "            },\n",
    "            \"letter\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The letter to count\"\n",
    "            }\n",
    "            \n",
    "        },\n",
    "        \"required\": [\"word\", \"letter\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f455913c-d06d-4429-af34-45d5cf62b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "course_price = {\"ai\": \"$119\", \"python\": \"$49\", \"machine learning\": \"$99\", \"llm\": \"$199\"}\n",
    "\n",
    "def get_online_course_price(online_course):\n",
    "    print(f\"-> Tool: get_online_course_price is called for course => {online_course}\\n\")\n",
    "    \n",
    "    course = online_course.lower()\n",
    "    return course_price.get(course, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c71ebd-b1db-48f3-ae6c-599a2a9386b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Tool: get_online_course_price is called for course => LLM\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$199'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_online_course_price(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714cf419-9e97-41b8-85d2-4393ef950f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_online_course_price\",\n",
    "    \"description\": \n",
    "        \"Retrieve the price of an online course. \"\n",
    "        \"Call this tool only when the user asks about course prices, \"\n",
    "        \"such as 'What is the price of AI Ethics course?' or \"\n",
    "        \"'How much does the Python course cost?'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"online_course\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \n",
    "                    \"The online course that the customer wants to take.\"\n",
    "                    \"The exact name of the online course (e.g., 'AI', 'Python', 'LLM'). \"\n",
    "                    \"Do NOT include extra words like 'course', 'class', or 'training'.\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"online_course\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014c57ea-02bd-400a-bb59-22922ed9a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools API can call\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": count_function}, \n",
    "    {\"type\": \"function\", \"function\": price_function}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d45438b4-3c2d-44d1-8d35-c6b8ac185c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    # Convert to dict using the `.model_dump()` method (recommended for OpenAI SDK v1+)\n",
    "    response_dict = response.model_dump()\n",
    "\n",
    "    print(\"Full Response Tree:\")\n",
    "    print(json.dumps(response_dict, indent=2))\n",
    "\n",
    "    print(\"\\nMessage Tree:\")\n",
    "    print(json.dumps(response_dict['choices'][0]['message'], indent=2))\n",
    "\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        tool_messages = []\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "\n",
    "            # tool_calls=[ChatCompletionMessageToolCall(id='call_mBxqr2fMPiYXppOtBnytGydo', \n",
    "            # function=Function(arguments='{\"online_course\":\"LLM\"}', \n",
    "            # name='get_online_course_price'), type='function')]))], \n",
    "            function_name = tool_call.function.name\n",
    "            \n",
    "            # arguments = {'online_course': 'LLM'}, a Python dictionary, from a json string\n",
    "            # arguments = json.loads('{\"online_course\":\"LLM\"}')\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            # Route to correct function\n",
    "            if function_name == \"count_letter_in_word\":\n",
    "                result = count_letter_in_word(**arguments)\n",
    "                pprint(f\"{function_name} result => {result}\")\n",
    "            elif function_name == \"get_online_course_price\":\n",
    "                # if arguments = {'online_course': 'LLM'}, \n",
    "                # then **arguments is equivalent to calling the function with online_course=\"LLM\".\n",
    "                result = get_online_course_price(**arguments)\n",
    "                pprint(f\"{function_name} result => {result}\")\n",
    "                print(result)\n",
    "                print()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknow tool: {function_name}\")\n",
    "\n",
    "            tool_response ={\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": json.dumps(result)\n",
    "            }\n",
    "            print(type(tool_response))\n",
    "            pprint(f\"tool_response => {tool_response}\")\n",
    "            print()\n",
    "            tool_messages.append(tool_response)\n",
    "            \n",
    "        # Convert to dict using the `.model_dump()` method (recommended for OpenAI SDK v1+)\n",
    "        messages.append(response.choices[0].message.model_dump())\n",
    "\n",
    "        print(\"Full message w/o tool_message Tree:\")\n",
    "        print(json.dumps(messages, indent=2))\n",
    "        \n",
    "        messages.extend(tool_messages)\n",
    "        print(\"Full message w/ tool_message Tree:\")\n",
    "        print(type(messages))\n",
    "        print(json.dumps(messages, indent=2))\n",
    "        \n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        # Convert to dict using the `.model_dump()` method (recommended for OpenAI SDK v1+)\n",
    "        response_dict = response.model_dump()\n",
    "        print(\"Full response after call tool Tree:\")\n",
    "        print(json.dumps(response_dict, indent=2))\n",
    "        \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abc5dce8-3910-4b27-bd4c-b51964256b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7883\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Response Tree:\n",
      "{\n",
      "  \"id\": \"chatcmpl-BYEzaNiHwFUFTUp51rzQ6fb7E4WGq\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_PgIO8nATST7BQw6S8XCL7VC5\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"online_course\\\":\\\"LLM\\\"}\",\n",
      "              \"name\": \"get_online_course_price\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1747500482,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_54eb4bd693\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 18,\n",
      "    \"prompt_tokens\": 332,\n",
      "    \"total_tokens\": 350,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Message Tree:\n",
      "{\n",
      "  \"content\": null,\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"annotations\": [],\n",
      "  \"audio\": null,\n",
      "  \"function_call\": null,\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"id\": \"call_PgIO8nATST7BQw6S8XCL7VC5\",\n",
      "      \"function\": {\n",
      "        \"arguments\": \"{\\\"online_course\\\":\\\"LLM\\\"}\",\n",
      "        \"name\": \"get_online_course_price\"\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "-> Tool: get_online_course_price is called for course => LLM\n",
      "\n",
      "'get_online_course_price result => $199'\n",
      "$199\n",
      "\n",
      "<class 'dict'>\n",
      "(\"tool_response => {'role': 'tool', 'tool_call_id': \"\n",
      " '\\'call_PgIO8nATST7BQw6S8XCL7VC5\\', \\'content\\': \\'\"$199\"\\'}')\n",
      "\n",
      "Full message w/o tool_message Tree:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You are a helpful assistant with access to two tools: 1) 'count_letter_in_word' - to count how many times a letter appears in a word or the sentance. Use this when the user asks questions like 'How many R's are in Strawberry?', or 'how many E's are in this sentence?'. 2) 'get_online_course_price' - to retrieve prices for online courses. Use this when the user asks about course prices like 'What is the price of AI Ethics course?'. Always pick the tool that best fits the user's question.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"LLM price\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"annotations\": [],\n",
      "    \"audio\": null,\n",
      "    \"function_call\": null,\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_PgIO8nATST7BQw6S8XCL7VC5\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"online_course\\\":\\\"LLM\\\"}\",\n",
      "          \"name\": \"get_online_course_price\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "<class 'list'>\n",
      "Full message w/ tool_message Tree:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You are a helpful assistant with access to two tools: 1) 'count_letter_in_word' - to count how many times a letter appears in a word or the sentance. Use this when the user asks questions like 'How many R's are in Strawberry?', or 'how many E's are in this sentence?'. 2) 'get_online_course_price' - to retrieve prices for online courses. Use this when the user asks about course prices like 'What is the price of AI Ethics course?'. Always pick the tool that best fits the user's question.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"LLM price\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"annotations\": [],\n",
      "    \"audio\": null,\n",
      "    \"function_call\": null,\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_PgIO8nATST7BQw6S8XCL7VC5\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"online_course\\\":\\\"LLM\\\"}\",\n",
      "          \"name\": \"get_online_course_price\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"tool_call_id\": \"call_PgIO8nATST7BQw6S8XCL7VC5\",\n",
      "    \"content\": \"\\\"$199\\\"\"\n",
      "  }\n",
      "]\n",
      "Full response after call tool Tree:\n",
      "{\n",
      "  \"id\": \"chatcmpl-BYEzaGDjHF42PdTfU5G2sCJByhd29\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"The price for the LLM course is $199.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1747500482,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_54eb4bd693\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 11,\n",
      "    \"prompt_tokens\": 160,\n",
      "    \"total_tokens\": 171,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b2e20-6b69-4ce7-ba75-0b81eb203a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a806e-080d-4307-8915-f7230c47528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af877f93-d580-4896-97b9-544346ab1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "# question = \"\"\"\n",
    "# Please explain what this code does and why:\n",
    "# yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "# \"\"\"\n",
    "# question = 'how does AI tool cursor work, be super brief please?'\n",
    "# question = 'how does git work, please be super brief? please translate to chinese.'\n",
    "\n",
    "# question = input(\"Enter your question: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8bff01a-03c2-4b69-bd89-f7cc2debc53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function looks rather simpler than the one from my video, because we're taking advantage of the latest Gradio updates\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09690154-2339-422c-ba6d-6dd6522bef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "\n",
    "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd159c41-d38b-4583-83e7-a227855a0910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please give a detailed explanation to the following question: how does AI tool cursor work, be super brief please?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067531e5-8374-412b-9aaf-7c3cde6308b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4584ae29-0fe1-4280-8b11-de73773897aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The AI tool \"Cursor\" works primarily as an integrated development environment (IDE) enhanced by artificial intelligence capabilities. It assists developers by providing features such as code suggestions, autocomplete, error detection, and real-time documentation. \n",
       "\n",
       "Here's a brief breakdown of its operation:\n",
       "\n",
       "1. **Context Awareness**: Cursor analyzes the context of the code being worked on, including the current file, libraries in use, and coding patterns.\n",
       "\n",
       "2. **AI Models**: It employs natural language processing and machine learning models trained on extensive codebases to understand coding syntax and semantics.\n",
       "\n",
       "3. **Code Suggestions**: As developers write code, Cursor predicts and suggests completions or corrections based on the learned patterns.\n",
       "\n",
       "4. **Integration**: The tool integrates with popular coding platforms and languages, allowing seamless use within the developer's workflow.\n",
       "\n",
       "5. **Learning and Adaptation**: Cursor may refine its suggestions as it learns from the user's coding style and preferences over time.\n",
       "\n",
       "Overall, Cursor aims to enhance productivity by making coding faster and more intuitive."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, w/o streaming\n",
    "def tutor():\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "          ]\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))\n",
    "    \n",
    "tutor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0675b28-52d7-42c0-be28-b5180ec258e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
