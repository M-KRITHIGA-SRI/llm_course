{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa646e3-7a57-461a-b69a-073179effa18",
   "metadata": {},
   "source": [
    "## Additional End of week Exercise - week 2\n",
    "\n",
    "This includes \n",
    "- Gradio UI\n",
    "- use of the system prompt to add expertise\n",
    "- audio input so you can talk to it\n",
    "- respond with audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f3dca4-b052-4e9f-90c8-f42e667c165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23570b9f-8c7a-4cc7-b809-3505334b60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d379178a-8672-4e6f-a380-ad8d85f5c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a personal study tutor, designed to provide clear, yet brief and succint answers to \n",
    "students that ask you questions. The topics are related to data science, computer science \n",
    "and technology in general, so you are allowed to use a moderate level of jargon. Explain in \n",
    "simple terminology, so a student can easily understand. \n",
    "\n",
    "You may also be asked about prices for special courses.In this case, respond that you have no such\n",
    "data available. \n",
    "\n",
    "\"\"\"\n",
    "# Use a tabular format where possible \n",
    "# for ease of information flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4745d439-c66e-4e5c-b5d4-9f0ba97aefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
    "    talker(reply)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b31799-df86-4151-98ea-66ef50fe767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper)\n",
      "  Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from openai-whisper) (4.67.1)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from openai-whisper) (0.9.0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (4.13.2)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from torch->openai-whisper) (2024.12.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from sympy!=1.13.2,>=1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/llms/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=d2d25219c1fc903e1f27307bd441251187c8d7c2c8cc6833300bc46b967c1dc4\n",
      "  Stored in directory: /Users/triimamwicaksono/Library/Caches/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, llvmlite, numba, openai-whisper\n",
      "Successfully installed llvmlite-0.44.0 more-itertools-10.7.0 numba-0.61.2 openai-whisper-20240930\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5b8e51-2833-44be-a4f4-63c4683f2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def transcribe_audio(audio):\n",
    "    if audio is None:\n",
    "        return \"No audio received.\"\n",
    "    \n",
    "    model = whisper.load_model(\"base\")  # You can use \"tiny\", \"small\", etc.\n",
    "    result = model.transcribe(audio)\n",
    "    \n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55f8e43-2da1-4f2a-bcd4-3fffa830db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3107a7-bfdc-4255-825f-bfabcf458c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=400,type=\"messages\")\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our StudyAI Assistant:\")\n",
    "    # with gr.Row():\n",
    "    #     entry = gr.Textbox(label=\"Speak or Type:\", placeholder=\"Speak your question...\", interactive=True, microphone=True)\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(type=\"filepath\", label=\"Speak your question\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    def handle_audio(audio, history):\n",
    "        text = transcribe_audio(audio)\n",
    "        history += [{\"role\": \"user\", \"content\": text}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=[chatbot], outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "    audio_input.change(handle_audio, inputs=[audio_input, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=[chatbot], outputs=[chatbot]\n",
    "    )\n",
    "    \n",
    "    clear.click(lambda: [], inputs=None, outputs=chatbot, queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e0a776-d43e-4b04-a37f-a27d3714cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd45503-d314-4b28-a41c-4dbb87059188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
