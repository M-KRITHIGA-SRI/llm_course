{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee5d9c-aa3b-42d6-b26d-cbae096a0571",
   "metadata": {},
   "source": [
    "# lets implement my base model\n",
    "\n",
    "## what do we need?\n",
    "- first of all import neccesary libraries\n",
    "- then write the main constants(.eg\\ base-url, system-prompt)\n",
    "- writing llm reponse funtion\n",
    "    - we have to use history in our conversation for gradio setup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cd85519-34ca-42ed-8e09-6c2347d55116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated (fa→en): سلام! پرواز به تهران دارید؟... → Hi! Do you have to fly to Tehr...\n",
      "\n",
      "📜 Conversation:\n",
      "SYSTEM: You are SafarBot, a bilingual flight assistant. \n",
      "Translate Persian<->English aut...\n",
      "USER: Hi! Do you have to fly to Tehran?\n",
      "\n",
      "🤖 LLM Response: Hello! I'm happy to help you with your travel plans.\n",
      "\n",
      "There is no need to translate this simple ques...\n",
      "Translated (en→fa): Hello! I'm happy to help you w... → سلام! خوشحالم که در برنامه های...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = 'http://localhost:11434/v1'\n",
    "MODEL = 'llama3.2'\n",
    "API_KEY = 'ollama'\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are SafarBot, a bilingual flight assistant. \n",
    "Translate Persian<->English automatically when needed.\"\"\"\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        self.translator = GoogleTranslator\n",
    "    \n",
    "    def translate(self, text: str, target_lang: str) -> str:\n",
    "        try:\n",
    "            source_lang = 'fa' if target_lang == 'en' else 'en'\n",
    "            result = self.translator(source=source_lang, target=target_lang).translate(text)\n",
    "            print(f\"Translated ({source_lang}→{target_lang}): {text[:30]}... → {result[:30]}...\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Translation failed: {e}\")\n",
    "            return text\n",
    "\n",
    "def print_chat(messages):\n",
    "    print(\"\\n📜 Conversation:\")\n",
    "    for msg in messages:\n",
    "        print(f\"{msg['role'].upper()}: {msg['content'][:80]}{'...' if len(msg['content']) > 80 else ''}\")\n",
    "    print()\n",
    "\n",
    "def chat(message: str, history: List[List[str]]) -> str:\n",
    "    translator = Translator()\n",
    "    client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "    \n",
    "    # Build message history\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "    for user_msg, bot_msg in history:\n",
    "        messages.extend([\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": bot_msg}\n",
    "        ])\n",
    "    \n",
    "    # Handle current message\n",
    "    is_persian = any(char in message for char in \"پچجحخهعغفقثصضشسیبلاتنمکگوئدذرزطظژؤإأءً\")\n",
    "    \n",
    "    if is_persian:\n",
    "        messages.append({\"role\": \"user\", \"content\": translator.translate(message, 'en')})\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    print_chat(messages)\n",
    "    \n",
    "    # Get LLM response\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    llm_response = response.choices[0].message.content\n",
    "    print(f\"🤖 LLM Response: {llm_response[:100]}...\")\n",
    "    \n",
    "    return translator.translate(llm_response, 'fa') if is_persian else llm_response\n",
    "\n",
    "# Launch the chat interface\n",
    "gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    title=\"✈️ SafarBot Flight Assistant\",\n",
    "    description=\"English/Persian flight booking assistant\",\n",
    "    examples=[\"Hello!\", \"سلام! پرواز به تهران دارید؟\"],\n",
    "    theme=\"soft\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a67d3-eac3-41dc-948e-3bdffa711d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
