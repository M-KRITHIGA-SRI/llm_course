{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of week 1 exercise\n",
        "\n",
        "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,\n",
        "and responds with an explanation. This is a tool that you will be able to use yourself during the course!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "import ollama\n",
        "import ipywidgets as widgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
            "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
            "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
            "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
            "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
            "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llama3.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# constants\n",
        "\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama3.2'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key looks good so far\n"
          ]
        }
      ],
      "source": [
        "# set up environment\n",
        "\n",
        "# Get the openai key\n",
        "\n",
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "if openai_api_key and openai_api_key.startswith('sk-proj-') and len(openai_api_key)>10:\n",
        "    print(\"API key looks good so far\")\n",
        "else:\n",
        "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
        "\n",
        "openai = OpenAI()\n",
        "# Get the ollama key using the llama model\n",
        "\n",
        "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"You are a knowledgeable technical instructor who helps students understand \\\n",
        "complex concepts across a wide range of technical topics. Your expertise includes artificial]\\\n",
        "intelligence, machine learning, large language models (LLMs), and programming in languages \\\n",
        "such as Python, JavaScript, Java, and more. You also provide in-depth support for \\\n",
        "AI engineering questions and other advanced technical subjects.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here is the question; type over this to ask something new\n",
        "\n",
        "question = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper to answer using selected model without duplicating logic\n",
        "\n",
        "def answer_question(question_text: str, model_choice: str):\n",
        "    if not question_text or not question_text.strip():\n",
        "        display(Markdown(\"**Please enter a question.**\"))\n",
        "        return\n",
        "\n",
        "    if model_choice == MODEL_GPT:\n",
        "        stream = openai.chat.completions.create(\n",
        "            model=MODEL_GPT,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": question_text},\n",
        "            ],\n",
        "            stream=True,\n",
        "        )\n",
        "        response_text = \"\"\n",
        "        handle = display(Markdown(\"\"), display_id=True)\n",
        "        for chunk in stream:\n",
        "            response_text += chunk.choices[0].delta.content or \"\"\n",
        "            response_text = response_text.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
        "            update_display(Markdown(response_text), display_id=handle.display_id)\n",
        "        return\n",
        "\n",
        "    if model_choice == MODEL_LLAMA:\n",
        "        response = ollama_via_openai.chat.completions.create(\n",
        "            model=MODEL_LLAMA,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": question_text},\n",
        "            ],\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "        display(Markdown(result))\n",
        "        return\n",
        "\n",
        "    display(Markdown(f\"Unknown model: {model_choice}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Certainly! The code snippet you provided is a Python expression that uses a combination of a generator, a set comprehension, and a conditional filter. Let’s break it down step by step.\n",
              "\n",
              "### Components of the Code\n",
              "\n",
              "1. **`books`**: This is assumed to be an iterable, likely a list of dictionaries, where each dictionary represents a book with various attributes (like title, author, etc.).\n",
              "\n",
              "2. **`book.get(\"author\")`**: This is a method call that retrieves the value associated with the key `\"author\"` from each `book` dictionary. If the `\"author\"` key is not present, `book.get()` will return `None`.\n",
              "\n",
              "3. **Set Comprehension**: The expression `{book.get(\"author\") for book in books if book.get(\"author\")}` creates a set of authors from the `books`. The `if book.get(\"author\")` condition ensures that only books where an author is defined (non-`None`) are included in the set. This means the result will only contain unique author names, as sets do not allow duplicate entries.\n",
              "\n",
              "4. **`yield from`**: This keyword is part of Python's generator function syntax. It allows you to yield all values from an iterable (in this case, the set of authors) one by one. \n",
              "\n",
              "### What the Code Does\n",
              "\n",
              "Putting it all together, this code does the following:\n",
              "\n",
              "- It generates a set of unique author names (`book.get(\"author\")`) from the provided `books` list, but only for those books that have a defined author.\n",
              "- By using `yield from`, the generator will yield each author name one at a time whenever the generator function is called.\n",
              "\n",
              "### Example\n",
              "\n",
              "For instance, if `books` is structured as follows:\n",
              "\n",
              "python\n",
              "books = [\n",
              "    {\"title\": \"Book A\", \"author\": \"Author 1\"},\n",
              "    {\"title\": \"Book B\", \"author\": \"Author 2\"},\n",
              "    {\"title\": \"Book C\", \"author\": \"Author 1\"},  # Duplicate\n",
              "    {\"title\": \"Book D\"},  # No author\n",
              "    {\"title\": \"Book E\", \"author\": \"Author 3\"}\n",
              "]\n",
              "\n",
              "\n",
              "The code would execute as follows:\n",
              "\n",
              "1. Create the set of authors: `{'Author 1', 'Author 2', 'Author 3'}`\n",
              "2. Yield each author when the generator is iterated over.\n",
              "\n",
              "### Why Use This Code?\n",
              "\n",
              "- **Efficiency**: It collects unique authors, which can be useful in scenarios where you only want distinct entries, eliminating duplicates effortlessly since sets handle this inherently.\n",
              "- **Memory Management**: Using `yield` allows for generating values on-the-fly, which can save memory when working with large datasets, as it does not require storing all the results in memory at once.\n",
              "- **Readability and Conciseness**: The combination of comprehensions and generators makes the code both concise and expressive, which can improve readability and maintainability.\n",
              "\n",
              "Overall, this code snippet is a Pythonic way to extract unique author names from a collection of book dictionaries while avoiding any unnecessary complexity."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get gpt-4o-mini to answer, with streaming\n",
        "answer_question(question, MODEL_GPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "This line of code is using a feature called \"generator expressions\" in Python, which is a concise way to create iterators.\n",
              "\n",
              "Here's a breakdown of what the code does:\n",
              "\n",
              "- `yield from`: This keyword is used when you want to delegate iteration over other items. It tells Python to yield values from another iterable.\n",
              "\n",
              "- `{book.get(\"author\") for book in books if book.get(\"author\")}`: This part creates a generator expression, which generates values on the fly and returns an iterator object.\n",
              "\n",
              "  - `for book in books`: This part iterates over each item (`book`) in the collection of `books`.\n",
              "\n",
              "  - `if book.get(\"author\")`: This condition filters out items that do not have an 'author' key. It uses the `.get()` method to safely retrieve the value, avoiding a `KeyError` if the key does not exist.\n",
              "\n",
              "  - `book.get(\"author\")`: This part of the expression retrieves the author from each book.\n",
              "\n",
              "The overall effect is to produce an iterator over the author names of books that have authors. \n",
              "\n",
              "In other words, this line of code creates an iterator over the authors of all books in the collection where the author exists. \n",
              "\n",
              "This generator expression can be used to simplify a loop and make it more expressive, as we don't need to manually iterate over the items with explicit loops.\n",
              "\n",
              "Here's how you could rewrite a simple loop using `yield from`:\n",
              "\n",
              "Before:\n",
              "```python\n",
              "author_names = []\n",
              "for book in books:\n",
              "    if book.get(\"author\"):\n",
              "        author_names.append(book.get(\"author\"))\n",
              "```\n",
              "After:\n",
              "```python\n",
              "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
              "# this would yield the same result, without needing an explicit loop.\n",
              "```\n",
              "\n",
              "However, keep in mind that using `yield from` and generator expressions will stop once the inner iterable does. So, you might need to make sure that's the desired behavior for your use case.\n",
              "\n",
              "Finally, note that `book.get(\"author\")` is called twice here (once when defining the generator expression and again when yielding the results). In Python 3.x, this can be problematic due to a feature known as \"surprise evaluation\" of function arguments. It can lead to unpredictable behavior in older versions of Python or if you're reusing the same `book` object across multiple calls.\n",
              "\n",
              "If you're able, consider defining the value twice separately and storing them individually. For instance:\n",
              "\n",
              "```python\n",
              "author_values = [book.get(\"author\") for book in books if book.get(\"author\")]\n",
              "yield from author_values\n",
              "```\n",
              "However, this avoids the problem of surprise evaluation. If you really need to use a generator expression or `yield from`, using it as part of an outer loop might mitigate some issues by having explicit control of when the outer function is called with values. This way you don't necessarily see the inner values being evaluated twice unless you want them to be. \n",
              "\n",
              "Note however that sometimes things might sound \"clever\" but may still potentially create problems or unexpected execution flows without properly thinking what should be the flow in your given scenario"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get Llama 3.2 to answer\n",
        "answer_question(question, MODEL_LLAMA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8e4d4e828754b558b9edc5a34e2c8ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Dropdown(description='Model:', options=(('GPT', 'gpt-4o-mini'), ('LLaMA', 'llama3.2')), value='…"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ipywidgets UI\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=[(\"GPT\", MODEL_GPT), (\"LLaMA\", MODEL_LLAMA)],\n",
        "    value=MODEL_GPT,\n",
        "    description=\"Model:\",\n",
        ")\n",
        "\n",
        "question_area = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"Ask your technical question here...\",\n",
        "    description=\"Question:\",\n",
        "    layout=widgets.Layout(width='100%', height='120px')\n",
        ")\n",
        "\n",
        "ask_button = widgets.Button(description=\"Ask\", button_style=\"primary\")\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def on_ask_clicked(_):\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        answer_question(question_area.value, model_dropdown.value)\n",
        "\n",
        "\n",
        "ask_button.on_click(on_ask_clicked)\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    model_dropdown,\n",
        "    question_area,\n",
        "    ask_button,\n",
        "    output,\n",
        "])\n",
        "\n",
        "ui\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
