{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1e828-6805-4f44-8474-58e768723af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e3406-b820-4ba9-b852-5ee7bc523ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748e340-b0b8-4a9a-82bb-f498bb90dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1bfb1-8d35-4931-b8b5-cd525c20adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b27bb9-a0a4-42b3-a603-6e0d3e252ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"You are a pen tester who tries to exploit vulnerabilities on a website and reports back with the findings that have been exploited\\\n",
    " , a description for each one and priority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00163d-a006-4fef-ada0-9f9077901f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(url):\n",
    "    user_prompt= f\"You are looking at a website with this url {url}\"\n",
    "    user_prompt+=\"\\n Please, provide all the findings that can possibly be found on this website\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79685242-6ba6-43c2-a9b1-da54c6a87347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt_for(\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9d45e-6fe1-4de5-9878-30659047dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(url):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(url)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab9340-f96b-44ae-b75f-f4cbcda25483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(url):\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = \"llama3.2\",\n",
    "        messages = messages_for(url)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a839d-de1b-41f9-bc60-000da6c4e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan(\"https://edwarddonner.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
