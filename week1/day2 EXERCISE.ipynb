{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as blog posts, social media posts, product descriptions, and even entire articles. This can help businesses save time and money on content creation.\n",
      "2. **Design and Visual Content**: Generative AI can be used to create custom designs for products, packaging, branding materials, and more. It can also generate images, logos, and graphics with unprecedented speed and accuracy.\n",
      "3. **Marketing Automation**: Generative AI can be used to automate marketing tasks such as lead generation, email marketing, and social media posting. This can help businesses save time and resources on manual marketing efforts.\n",
      "4. **Personalized Customer Experience**: Generative AI can be used to generate personalized content for customers based on their preferences, behavior, and demographics. This can help businesses improve customer engagement and loyalty.\n",
      "5. **Data Analysis and Insights**: Generative AI can be used to analyze large datasets and generate insights that can inform business decisions. This can help businesses identify trends, patterns, and opportunities for growth.\n",
      "6. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can provide 24/7 customer support and answer common questions. This can help businesses improve customer satisfaction and reduce support costs.\n",
      "7. **Product Development and Engineering**: Generative AI can be used to generate new product designs, prototypes, and testing simulations. This can help businesses accelerate the product development process and reduce costs.\n",
      "8. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, managing inventory, and identifying bottlenecks. This can help businesses improve efficiency and reduce costs.\n",
      "9. **Financial Modeling and Forecasting**: Generative AI can be used to generate financial models and forecasts that can help businesses predict future revenue and expenses. This can help businesses make informed investment decisions and avoid financial risks.\n",
      "10. **Cybersecurity Threat Detection**: Generative AI can be used to detect and respond to cybersecurity threats in real-time. This can help businesses improve their security posture and reduce the risk of data breaches.\n",
      "\n",
      "Some specific business use cases for Generative AI include:\n",
      "\n",
      "* **Amazon's Product Recommendation Engine**: Amazon uses generative AI to generate personalized product recommendations based on customer behavior and preferences.\n",
      "* **Google's Image Generation Model**: Google uses generative AI to generate high-quality images that can be used in search results, advertising, and other applications.\n",
      "* **Baidu's DuerOS Chatbot**: Baidu uses generative AI to create chatbots that can provide 24/7 customer support and answer common questions.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases emerge.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI (also known as Generative Models or Generative Adversarial Networks, GANs) has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as:\n",
      " * Articles and blog posts\n",
      " * Social media posts\n",
      " * Product descriptions\n",
      " * Video scripts\n",
      " * Music and audio tracks\n",
      "2. **Image and Video Generation**: Generative AI can be used to create realistic images and videos for:\n",
      " * Product photography\n",
      " * Advertising campaigns\n",
      " * Virtual try-on experiences\n",
      " * Storytelling in e-learning platforms\n",
      "3. **Chatbots and Customer Service**: Generative AI-powered chatbots can:\n",
      " * Provide 24/7 customer support\n",
      " * Offer personalized recommendations\n",
      " * Help with transactions and order fulfillment\n",
      "4. **Data Analysis and Visualization**: Generative AI can be used to analyze and visualize complex data sets, such as:\n",
      " * Financial market analysis\n",
      " * Weather forecasting\n",
      " * Medical diagnosis\n",
      "5. **Product Design and Development**: Generative AI can be used to create new product designs and prototypes, reducing the need for physical prototyping.\n",
      "6. **Marketing Automation**: Generative AI can help automate marketing tasks, such as:\n",
      " * Personalized email campaigns\n",
      " * Social media advertising\n",
      " * Influencer identification\n",
      "7. **Creative Writing and Storytelling**: Generative AI can be used to generate creative writing, such as poetry, short stories, or even entire books.\n",
      "8. **Music Composition**: Generative AI can be used to compose music for:\n",
      " * Advertising campaigns\n",
      " * Video games\n",
      " * Film scores\n",
      "9. **Game Development**: Generative AI can be used to create procedural content, such as levels, characters, and environments, for video games.\n",
      "10. **Cybersecurity**: Generative AI can be used to detect and respond to cyber threats in real-time, improving the efficiency of incident response.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation:** Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation while maintaining consistency and quality.\n",
      "2. **Product Design:** AI-powered generative designs can create prototypes for new products, allowing designers to quickly test and refine ideas without the need for expensive prototyping and testing processes.\n",
      "3. **Marketing Copywriting:** Generative AI can also be used to generate high-quality marketing copy, such as email subject lines, product pitches, and advertising scripts, that are tailored to specific target audiences.\n",
      "4. **Social Media Management:** AI-powered generative tools can help businesses create engaging social media content, such as videos, images, and posts, that resonate with their audience.\n",
      "5. **Influencer Research and Outreach:** Generative AI can be used to identify potential influencers for a brand, generate outreach emails, and compose scripts for those interactions.\n",
      "6. **User Interface (UI) Design:** AI-powered generative tools can create intuitive and user-friendly UI designs for applications, websites, and software products.\n",
      "7. **Image and Video Generation:** Generative AI can be used to create high-quality images and videos for use in marketing materials, product catalogs, or website sliders.\n",
      "8. **Data Annotation and Labeling:** Generative AI can be used to automatically annotate and label data, such as text, images, or audio files, which can reduce the time and effort required for manual annotation processes.\n",
      "9. **Quality Control and Inspection:** Generative AI-powered tools can analyze product designs, inspect defects, and predict potential quality issues, allowing businesses to optimize their production processes.\n",
      "10. **Employee Productivity and Collaboration:** Generative AI can be used to help employees with tasks such as report writing, data analysis, and document generation, freeing up time for more strategic work.\n",
      "\n",
      "Some specific industries that are leveraging generative AI include:\n",
      "\n",
      "1. **Media and Entertainment:** AI-powered tools for video production, content creation, and music composition\n",
      "2. **Finance and Banking:** AI-powered chatbots, risk assessment, and compliance management\n",
      "3. **Healthcare:** AI-powered medical imaging analysis, clinical trial research, and personalized medicine\n",
      "4. **Retail and Supply Chain:** AI-powered inventory optimization, demand forecasting, and supply chain logistics\n",
      "\n",
      "These examples illustrate the vast potential of generative AI to transform business operations across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"ollama\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to define the key concepts behind Large Language Models (LLMs), focusing on something called \"neural networks,\" \"attention,\" and \"transformers.\" Hmm. Let me think about this step by step.\n",
      "\n",
      "Starting with neural networks... I remember that LLMs are a type of AI model based on these neural network technologies. I think they process information through layers of nodes, or neurons, similar to the way our brains work for recognizing patterns. Each layer processes data sequentially until it's processed in parallel. But wait, what makes them \" intelligent\"? I recall that each neuron has some memory, or context, and can learn from examples. Plus, weights are adjusted during training using backpropagation. This self-supervised learning aspect is probably crucial because without that, traditional neural networks just pass through the data.\n",
      "\n",
      "Next, attention. If this is talking about Transformers as well, I remember \"attention\" is a key mechanism developed by researchers like Bahdanau and Greff. So, in an LLM with transformers, attention allows each model's decoder (or head) to focus on different parts of the input during processing. For example, if it's translating text from Chinese to English, the model can highlight certain words or phrases that are important. This is probably done by transforming the sequential data into a context-sensitive distribution matrix.\n",
      "\n",
      "Then there's the transformer itself. From what I learn, transformers use layers of multi-head attention and feed-forward networks, which process information in two different ways—each head focuses on a different part of the \"bag of tricks\" or operations. This structure allows models to focus on various information sources at any time. The self-attention part means each token (data point) in the sequence can pay attention to all others, creating a powerful way to process sequences by comparing every piece's impact. Since they deal with sequential data, they don't need recurrent connections or memory gates like LSTMs do.\n",
      "\n",
      "Wait, what about general neural networks? They have layers of nodes connected to each other to capture features and relations. Each node (neuron) processes its input through an activation function, passing information to the next layer until the output is produced. Through backpropagation during training, weights are updated based on loss functions, allowing the model to learn from data effectively.\n",
      "\n",
      "To wrap it up, neural networks are the broad category of models using layers and nodes for sequential processing with features extracted by connected layers. Attention in Transformers enables focused processing of sequences through multi-heads handling relationships between elements. Transferring these modules into LLMs allows them to process text at scale, adapting and self-limiting through self-supervised learning.\n",
      "</think>\n",
      "\n",
      "**Core Concepts in Large Language Models (LLMs):**\n",
      "\n",
      "1. **Neural Networks:**\n",
      "   - Neural networks are computational models composed of layers and nodes, where each node processes information sequentially or in parallel. They use memory to capture context and adjust weights during training with backpropagation. Self-supervised learning is crucial for them to self-activate through example data.\n",
      "\n",
      "2. **Attention (Transformer's Key Mechanism):**\n",
      "   - Attention allows models to focus on different segments of input data during processing, particularly effective in translating text from one language to another by highlighting relevant phrases or words.\n",
      "\n",
      "3. **Transformers:**\n",
      "   - Transformers use layers with multi-head attention for focused processing of sequences, enabling each element to compare and influence every other piece through sequential information handling without reliance on recurrent networks or memory gates.\n",
      "\n",
      "**Aggregate Overview:**\n",
      "Neural networks are models using sequential layers to process data with context through connected transformations. Transformers enhance this by introducing multi-head attention in sequential data transforms, allowing focused processing of input sequences. These components together enable LLMs to adapt and learn from self-supervised training scales efficiently.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def summarize(url, model):\n",
    "    website = Website(url)\n",
    "    if model == \"llama3.2\":\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.2\",\n",
    "            messages = messages_for(website)\n",
    "        )\n",
    "        return response['message']['content']\n",
    "        \n",
    "    if model == \"openai\":\n",
    "        response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    if model == \"deepseek\":\n",
    "        response = ollama_via_openai.chat.completions.create(\n",
    "        model=\"deepseek-r1:1.5b\",\n",
    "        messages = messages_for(website)\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    else:\n",
    "        print(f\"Model {model} is not currently supported for summarisation. Please choose one of 'openai', 'llama3.2' or 'deepseek'.\")\n",
    "              \n",
    "def display_summary(url, model):\n",
    "    summary = summarize(url, model)\n",
    "    display(Markdown(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd7ac78-d2b3-49b1-9726-18905d3420a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Website Summary\n",
       "=====================================\n",
       "\n",
       "The website \"Home - Edward Donner\" appears to be a personal blog or profile of its creator, Ed. The content is mostly about his interests and work in the field of Artificial Intelligence (AI), particularly Large Language Models (LLMs).\n",
       "\n",
       "## Key Points\n",
       "\n",
       "* Ed is the co-founder and CTO of Nebula.io, an AI startup that applies LLMs to help people discover their potential.\n",
       "* He has previously founded and led another AI startup, untapt, which was acquired in 2021.\n",
       "* The website features news and announcements about Ed's projects and endeavors, including:\n",
       "\t+ LLM Workshop – Hands-on with Agents (January 23, 2025)\n",
       "\t+ Welcome, SuperDataScientists! (November 13, 2024)\n",
       "\t+ Mastering AI and LLM Engineering – Resources (October 16, 2024)\n",
       "* Ed is active on social media platforms such as LinkedIn, Twitter, Facebook, and has a newsletter subscription.\n",
       "\n",
       "## Tone and Style\n",
       "\n",
       "The website has a casual and conversational tone, with Ed sharing his thoughts on various topics related to AI and technology. The content appears to be geared towards enthusiasts and professionals in the field of AI and machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\", \"llama3.2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
