{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as blog posts, social media posts, product descriptions, and more. This saves time and resources for businesses, allowing them to focus on high-level strategy and creativity.\n",
      "\n",
      "2. **Image and Video Creation**: Generative AI can create stunning images and videos that are indistinguishable from those created by humans. This is particularly useful in industries such as advertising, marketing, and entertainment.\n",
      "\n",
      "3. **Chatbots and Virtual Assistants**: AI-powered chatbots can help businesses automate customer support, provide 24/7 assistance, and even sell products or services to customers.\n",
      "\n",
      "4. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate insights that help businesses make informed decisions. This includes creating interactive visualizations to present complex data in a clear and concise manner.\n",
      "\n",
      "5. **Marketing Automation**: AI-powered tools can create personalized marketing campaigns, automate lead generation, and even predict customer behavior based on historical data.\n",
      "\n",
      "6. **Product Design and Development**: Generative AI can aid in product design by generating 3D models, prototypes, and even entire product lines. This saves time and resources for businesses, allowing them to focus on more complex tasks such as marketing and sales.\n",
      "\n",
      "7. **Recommendation Systems**: AI-powered recommendation systems can suggest products or services based on a customer's browsing history, purchase behavior, and other factors. This helps businesses increase sales and improve customer satisfaction.\n",
      "\n",
      "8. **Cybersecurity**: Generative AI can be used to detect and prevent cyber threats by analyzing network traffic, identifying patterns, and even generating predictive models of potential attacks.\n",
      "\n",
      "9. **Supply Chain Optimization**: AI-powered tools can analyze data from various sources to optimize supply chain operations, predict demand, and identify areas for improvement.\n",
      "\n",
      "10. **Human Resources and Recruitment**: Generative AI can help with tasks such as resume screening, candidate matching, and even generating interview questions that are tailored to a company's specific needs.\n",
      "\n",
      "11. **Financial Analysis and Forecasting**: AI-powered tools can analyze financial data, generate forecasts, and even identify potential risks or opportunities for businesses.\n",
      "\n",
      "12. **Customer Service and Support**: Generative AI can create personalized customer service experiences by analyzing customer behavior, preferences, and pain points.\n",
      "\n",
      "13. **Education and Learning**: AI-powered tools can create customized learning experiences, generate adaptive assessments, and even help with grading and feedback.\n",
      "\n",
      "14. **Healthcare and Medical Research**: Generative AI can aid in medical research by generating hypotheses, predicting patient outcomes, and even creating personalized treatment plans.\n",
      "\n",
      "15. **Environmental Sustainability**: AI-powered tools can analyze environmental data, predict climate patterns, and even generate strategies for reducing carbon emissions and promoting sustainability.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and even entire books.\n",
      "2. **Product Design**: Generative AI-powered design tools can create 3D models, product designs, and user interfaces for various products, reducing the need for manual design.\n",
      "3. **Marketing Automation**: Generative AI can be used to generate personalized marketing content, such as emails, advertisements, and social media posts, based on customer data and preferences.\n",
      "4. **Sales Chatbots**: Generative AI-powered chatbots can engage with customers, provide product information, and even make sales pitches.\n",
      "5. **Image and Video Generation**: Generative AI can be used to create realistic images and videos for various applications such as advertising, entertainment, and education.\n",
      "6. **Predictive Analytics**: Generative AI can analyze large datasets to predict customer behavior, detect anomalies, and identify patterns.\n",
      "7. **Virtual Assistants**: Generative AI-powered virtual assistants can be used in various industries such as healthcare, finance, and customer service.\n",
      "8. **Creative Writing**: Generative AI can be used to generate creative writing such as poetry, short stories, and even entire scripts.\n",
      "9. **Data Analysis**: Generative AI can be used to analyze large datasets and identify patterns, trends, and correlations that may not be apparent through traditional analysis methods.\n",
      "10. **Business Process Automation**: Generative AI can automate business processes by generating reports, invoices, and other documents based on data.\n",
      "\n",
      "Some of the industries that are already leveraging generative AI include:\n",
      "\n",
      "1. **Finance**: Generative AI is being used to detect credit risk, identify investment opportunities, and generate financial models.\n",
      "2. **Healthcare**: Generative AI is being used to analyze medical images, predict patient outcomes, and develop personalized treatment plans.\n",
      "3. **Retail**: Generative AI is being used to personalize product recommendations, generate marketing content, and automate customer service.\n",
      "4. **Marketing**: Generative AI is being used to create targeted advertising campaigns, generate social media content, and analyze customer behavior.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content, such as blog posts, social media posts, product descriptions, and more. This helps businesses save time, reduce costs, and increase consistency in their content.\n",
      "2. **Virtual Assistants**: Generative AI enables the creation of virtual assistants that can chat with customers, answer FAQs, and provide customer support. These virtual assistants can be integrated into different platforms, such as websites, mobile apps, or voice assistants.\n",
      "3. **Personalization**: AI-powered algorithms can generate personalized content, recommendations, and offers based on customer behavior, preferences, and demographics. This helps businesses improve customer engagement, increase sales, and enhance the overall user experience.\n",
      "4. **Design and Prototyping**: Generative AI can automate design tasks, such as logo creation, graphic editing, and product design. This enables designers to focus on high-level creative decisions while relying on AI for execution.\n",
      "5. **Marketing Automation**: AI-powered tools can generate marketing materials, create targeted campaigns, and optimize ad targeting based on real-time customer data. This helps businesses streamline their workflow, increase efficiency, and improve ROI.\n",
      "6. **Customer Service Chatbots**: Generative AI enables the creation of conversational chatbots that can handle multiple conversations simultaneously, provide empathetic responses, and offer personalized support to customers.\n",
      "7. **Predictive Maintenance**: AI-powered predictive maintenance tools can analyze sensor data from machines, predict potential failures, and suggest maintenance schedules. This helps businesses reduce downtime, optimize resource allocation, and improve overall equipment efficiency.\n",
      "8. **Music and Audio Generation**: AI-generated music and audio content can be used in various industries, such as videogaming, film production, and advertising. This opens up new creative possibilities for filmmakers, advertisers, and musicians.\n",
      "9. **Data Augmentation**: Generative AI tools can augment existing datasets with new data generated by AI, helping businesses improve the accuracy and diversity of their training data.\n",
      "10. **Creative Writing**: AI-powered writing tools can generate novel content, such as product descriptions, marketing copy, or even entire articles. This helps businesses save time writing high-quality content while maintaining consistency.\n",
      "\n",
      "Industries that benefit from Generative AI include:\n",
      "\n",
      "1. Digital Marketing\n",
      "2. Content Creation (Media & Entertainment)\n",
      "3. Customer Service (Contact Centers)\n",
      "4. Product Development (Manufacturing & Design)\n",
      "5. Sales and Account Management (SaaS & B2B)\n",
      "6. Finance (Financial Analysis & Reporting)\n",
      "7. Healthcare (Patient Data Analysis & Research)\n",
      "8. Education (Curriculum Development & Tutoring)\n",
      "\n",
      "These applications demonstrate the vast potential of Generative AI to transform business operations, improve efficiency, and drive growth across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand the key components that make up Large Language Models (LLMs). The user has asked for definitions for \"neural network,\" \"attention,\" and \"transformer.\" Hmm, I've heard before about transformers being used in LLMs, but I’m not super familiar with them. Let me think this through step by step.\n",
      "\n",
      "Starting with neural networks as a core concept. From what I remember, a neural network is kind of like the brain of an AI model. It consists of layers of neurons connected together, and each layer processes information in a certain way. In traditional machine learning, sometimes you just train your model on data without much structure. But neural networks probably put structure into the model by having multiple layers with shared weights, which allows each layer to learn more complex features through backpropagation.\n",
      "\n",
      "In the context of LLMs, maybe it's not just any kind of neural network but a type that's designed for sequential tasks. Unlike convolutional neural networks (CNNs) used in image recognition, which work on 2D data like images, an RNN is better for unstructured sequences. So perhaps the neural network here isn't static but dynamic over time and sequences.\n",
      "\n",
      "Next up is attention. I've heard of it before in the context of models like BERT or others. It's a method where each word or token in the input can \"focus\" on different parts of the input when making decisions. This seems similar to how humans process language, focusing more on what they care about. Instead of treating all words as equally important, attention allows models to weigh their importance based on context.\n",
      "\n",
      "Then there's the Transformer component. I think it's a key system within LLMs that helps with processing sequential data. The word \"transform\" is familiar if you've read about GPT's use of it in their architecture. Transformers have this structure where each position in the sequence is processed using self-attention mechanisms. This seems different from traditional RNNs because it processes all attention weights at once rather than step by step, which helps with parallel computation and capturing long-range dependencies.\n",
      "\n",
      "Wait, are these related or building upon each other? Maybe each part feeds into another. Like, an attention mechanism could be embedded inside a layer of a Transformer, perhaps along with some feed-forward layers for the positional encoding. The overall architecture combines these elements to handle tasks from text to speech and more.\n",
      "\n",
      "I'm not sure about all the specifics, like what GPT uses. They might use multiple attention heads or other mechanisms, but at lower levels, it's likely the basic approach. To make sure I understand correctly: the neural network (maybe an RNN initially) processes sequential data with time steps. Then, transformers improve this by breaking down each input into self-attention focusing on different parts, while RNNs are simpler layers that remember states from previous steps.\n",
      "\n",
      "I should try to outline these components one at a time and then see how they come together in LLM models.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs) are complex systems designed to understand and generate human languages. Here's a structured breakdown of the key concepts, including neural networks, attention mechanisms, and transformers:\n",
      "\n",
      "1. **Neural Network**:\n",
      "   - A collection of interconnected neurons organized into layers that process information sequentially or in parallel.\n",
      "   - Used traditionally for static tasks, but within LLMs, they're dynamic, evolving over time with sequence processing.\n",
      "\n",
      "2. **Attention Mechanism**:\n",
      "   - Focuses on assigning higher weights to relevant parts of the input while ignoring less important information.\n",
      "   - Inspired by human attention, it enables models to process sequences or text dynamically.\n",
      "\n",
      "3. **Transformer Structure (in LLMs)**:\n",
      "   - A system that processes each sequence in one pass without step-wise processing.\n",
      "   - Uses self-attention mechanisms and parallel computation within its layers, enhancing efficiency for long-range dependencies like those found in reasoning tasks.\n",
      "\n",
      "4. **Integration of Components**:\n",
      "   - Initially an RNN due to time structure, evolved by transformers which process all attention weights simultaneously.\n",
      "   - LLMs combine these elements with additional features like multi-head attention or positional learning to enhance performance.\n",
      "\n",
      "These components work together to transform sequential data into coherent outputs, crucial for tasks ranging from text generation to advanced linguistic understanding.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5a5188-6198-423e-8e30-30696751d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8865d83b-140a-48c5-aab1-fb4dc5f1f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "# If this doesn't work, try Kernel menu >> Restart Kernel and Clear Outputs Of All Cells, then run the cells from the top of this notebook down.\n",
    "# If it STILL doesn't work (horrors!) then please see the Troubleshooting notebook in this folder for full instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6dc426-a22b-41d0-b9fb-cc026d7fd333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! I'm glad to receive your message. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636cef38-bb2c-4931-973f-0a47739ac047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ac6d43-2946-43f7-901a-68c88dfc67e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c263754d-70d3-47fb-85c1-470778310353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a65a83-d789-4721-b190-0e9c189c0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2f03da-cb74-4745-9283-0127d12e2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9500c914-104f-4f7d-8bf7-1331e7fa93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e95c9dc-f3e6-4435-9c8e-8af0c6f0db8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6653ac6-70b7-4cf9-b620-287fa9b985a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c075f970-7919-4c37-a7df-d08285aac3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Summary of Edward Donner's Website\\n\\nThe website belongs to Edward Donner, a software developer with a focus on large language models (LLMs) and artificial intelligence. He is the co-founder and CTO of **Nebula.io**, a company that leverages AI to assist in talent discovery and engagement. Previously, he founded **untapt**, an AI startup that was acquired in 2021. In addition to programming, Ed enjoys DJing and electronic music production.\\n\\n## Upcoming Events\\n- **May 18, 2025**: AI Executive Briefing\\n- **April 21, 2025**: Complete Agentic AI Engineering Course\\n- **January 23, 2025**: LLM Workshop – Hands-on with Agents – Resources\\n- **December 21, 2024**: Welcome, SuperDataScientists!\\n\\nOverall, the website provides insights into Ed's professional background, interests, and upcoming educational events related to AI and LLMs.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55b276c7-c5ca-4b5c-8c75-f64072312e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed8c542-e625-4e91-bb51-adb235932d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "Edward Donner's website introduces him as a software developer interested in coding and experimenting with Large Language Models (LLMs). He enjoys music production and follows technology news. He is the co-founder and CTO of Nebula.io, a company that utilizes AI to assist individuals in discovering their potential and engaging with talent management. Edward previously founded an AI startup called untapt, which was acquired in 2021.\n",
       "\n",
       "## News and Announcements\n",
       "- **May 18, 2025:** Announcement of the \"2025 AI Executive Briefing.\"\n",
       "- **April 21, 2025:** Launch of the \"Complete Agentic AI Engineering Course.\"\n",
       "- **January 23, 2025:** \"LLM Workshop – Hands-on with Agents,\" with available resources.\n",
       "- **December 21, 2024:** A welcome message to \"SuperDataScientists!\"\n",
       "\n",
       "For more personal insights or inquiries, Edward provides contact details for connecting."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b9a479d-f356-48ac-aa05-986b26dcec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_via_ollama(url):\n",
    "    website = Website(url)    \n",
    "    messages = messages_for(website)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "       \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ee3749-9319-40ca-800e-3fe081c80a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary_via_ollama(url):\n",
    "    summary = summarize_via_ollama(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a93419bd-5cfe-4473-bea7-c2d6b44de096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Website Summary**\n",
       "=====================\n",
       "\n",
       "### About the Author\n",
       "\n",
       "*   **Edward Donner**: The website's author and co-founder/CTO of Nebula.io. He has experience as a founder and CEO of AI startup untapt, acquired in 2021.\n",
       "\n",
       "### News and Announcements\n",
       "---------------------------\n",
       "\n",
       "*   **Upcoming Events**:\n",
       "    *   \"2025 AI Executive Briefing\" (May 18, 2025)\n",
       "    *   \"The Complete Agentic AI Engineering Course\" (January 23, 2025)\n",
       "    *   \"LLM Workshop – Hands-on with Agents – resources\" (December 21, 2024)\n",
       "\n",
       "### Product and Service Overview\n",
       "\n",
       "*   Nebula.io applies AI to help people discover their potential and pursue their reason for being.\n",
       "*   The company provides a platform for recruiters to source, understand, engage, and manage talent.\n",
       "*   A proprietary matching model has been patented.\n",
       "\n",
       "### Contact Information\n",
       "\n",
       "*   Email: [ed at] edwarddonner [dot] com\n",
       "*   Website: www.edwarddonner.com\n",
       "*   Social Media Links:\n",
       "    *   LinkedIn\n",
       "    *   Twitter\n",
       "    *   Facebook"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary_via_ollama(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14f0b0-714c-4e8e-8ec7-eeb98f2c5825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
