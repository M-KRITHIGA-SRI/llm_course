{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# EXERCISE SOLUTION\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c153e54-bc96-436d-a632-5198cc553073",
   "metadata": {},
   "source": [
    "## Main diff from -copy1 file is the Website class, below is from Grok:\n",
    "https://grok.com/share/bGVnYWN5_625bf8cd-4900-4bb1-bc19-d6798a320bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f4d8d52-41d8-4eb6-a7ca-4d0fb18eb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a scraped website, storing its URL, title, and cleaned text content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, timeout: int = 10, headers: Optional[dict] = None):\n",
    "        \"\"\"\n",
    "        Initialize a Website object by scraping the given URL using BeautifulSoup.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website to scrape.\n",
    "            timeout (int, optional): Maximum time (in seconds) to wait for the HTTP request. Defaults to 10.\n",
    "            headers (dict, optional): Custom HTTP headers for the request. Defaults to a standard user-agent.\n",
    "\n",
    "        Raises:\n",
    "            RequestException: If the HTTP request fails (e.g., network error, invalid URL).\n",
    "            ValueError: If the URL is empty or malformed.\n",
    "        \"\"\"\n",
    "        if not url or not url.strip():\n",
    "            raise ValueError(\"URL cannot be empty\")\n",
    "        \n",
    "        self.url = url\n",
    "        # Use default headers if none provided\n",
    "        self.headers = headers or {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Fetch the webpage with timeout\n",
    "            response = requests.get(url, headers=self.headers, timeout=timeout)\n",
    "            response.raise_for_status()  # Raise exception for bad status codes (e.g., 404, 500)\n",
    "            \n",
    "            # Parse with BeautifulSoup\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # Extract title, fallback to domain if none found\n",
    "            self.title = (\n",
    "                soup.title.string.strip() if soup.title and soup.title.string\n",
    "                else urlparse(url).netloc or \"No title found\"\n",
    "            )\n",
    "            \n",
    "            # Remove irrelevant tags if body exists\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\", \"nav\", \"footer\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"\"\n",
    "                \n",
    "        except RequestException as e:\n",
    "            raise RequestException(f\"Failed to fetch {url}: {str(e)}\") from e\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error processing {url}: {str(e)}\") from e\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a string representation of the Website object.\n",
    "        \"\"\"\n",
    "        return f\"Website(url={self.url}, title={self.title}, text_length={len(self.text)})\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a detailed string representation for debugging.\n",
    "        \"\"\"\n",
    "        return f\"Website(url={self.url!r}, title={self.title!r}, text={self.text[:100]!r}...)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99174841-ba03-4920-8080-95e34489dc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music prod\n"
     ]
    }
   ],
   "source": [
    "website = Website(\"https://edwarddonner.com/\")\n",
    "print(website.title)  # Example Domain\n",
    "print(website.text[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6078e67f-373f-44e9-a89f-f59fd440b1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are looking at a website titled Home - Edward DonnerThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nNavigation\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_for(ed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from Ollama expects the same message format as OpenAI:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above - what Ollama API needs\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eab8eec9-7fb8-4efb-933e-6841220ef3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward DonnerThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nNavigation\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the actual website content, with system and user prompt, which includes user request and web content\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - now with Ollama instead of OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Ollama function instead of OpenAI\n",
    "# https://grok.com/share/bGVnYWN5_ae4c05fe-5ff7-4d1f-9b14-cd594d054c49\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url, timeout=10)  # Use the improved class\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary of Edward Donner\\'s Website**\\n=====================================\\n\\n*   **About**: Ed Donner is a co-founder and CTO of Nebula.io, an AI startup that applies AI to help people discover their potential. He enjoys writing code, DJing, and experimenting with LLMs.\\n*   **Recent News and Announcements**:\\n    *   **\"The Complete Agentic AI Engineering Course\"**: Released on April 21, 2025.\\n    *   **\"LLM Workshop – Hands-on with Agents – resources\"**: Released on December 21, 2024.\\n    *   **\"Mastering AI and LLM Engineering – Resources\"**: Released on November 13, 2024.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of Edward Donner's Website**\n",
       "=====================================\n",
       "\n",
       "### About the Creator\n",
       "\n",
       "* Ed is a tech enthusiast who enjoys writing code, experimenting with Large Language Models (LLMs), and DJing.\n",
       "* He co-founded Nebula.io, an AI startup applying LLMs to help people discover their potential.\n",
       "\n",
       "### Company Overview\n",
       "\n",
       "* Nebula.io: develops proprietary LLMs for talent sourcing, engagement, and management.\n",
       "* Previously founded AI startup untapt, acquired in 2021.\n",
       "\n",
       "### Recent News and Announcements\n",
       "---------------------------\n",
       "\n",
       "* **Course Announcement**: \"The Complete Agentic AI Engineering Course\" (April 21, 2025)\n",
       "* **Workshop Resource**: LLM Workshop – Hands-on with Agents (December 21, 2024)\n",
       "* **Community Welcome**: Welcome, SuperDataScientists! (November 13, 2024)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working\n",
    "# display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Anthropic Website Summary**\n",
       "=============================\n",
       "\n",
       "### Mission and Approach\n",
       "\n",
       "Anthropic aims to build AI that serves humanity's long-term well-being. They focus on designing powerful technologies with human benefit at their foundation, prioritizing responsible AI development.\n",
       "\n",
       "### Recent News and Announcements\n",
       "\n",
       "*   **Claude 3.7 Sonnet**: Anthropic has released its most intelligent AI model, Claude 3.7 Sonnet.\n",
       "*   **Research Updates**:\n",
       "    *   Tracing the thoughts of a large language model (March 27, 2025)\n",
       "    *   Anthropic Economic Index (March 27, 2025)\n",
       "    *   Alignment faking in large language models (December 18, 2024)\n",
       "*   **Product Releases**:\n",
       "    *   Claude’s extended thinking (February 24, 2025)\n",
       "    *   Introducing the Model Context Protocol (November 25, 2024)\n",
       "\n",
       "### Key Initiatives\n",
       "\n",
       "*   Anthropic Academy: Learn to build with Claude\n",
       "*   Responsible Scaling Policy\n",
       "\n",
       "This summary highlights Anthropic's mission, recent news and announcements, and key initiatives. It provides an overview of the website's content, excluding navigation-related sections."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55f9efd8-6f8b-4b07-9ecc-eecd7fd70b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working\n",
    "# display_summary(\"https://www.tesla.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "PR instructions courtesy of an AI friend: https://chatgpt.com/share/670145d5-e8a8-8012-8f93-39ee4e248b4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eff74-55c4-4d4b-b267-703edbc293c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
