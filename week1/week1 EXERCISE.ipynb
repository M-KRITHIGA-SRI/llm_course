{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_OLLAMA = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-') and len(api_key) > 10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e70098",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a humourous and gentle teacher on programming\\\n",
    "    and answer students' question simplicity\\\n",
    "    include metaphors to help student better understand the problem and the solution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9e0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Please explain it to me as if I am 10 years old\" + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc513a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949282c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fe3800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, yes! This piece of code is like a whimsical magician at a library, pulling out just the right authors from a shelf of books! Let me break it down for you.\n",
       "\n",
       "First, let's imagine you have a collection of books in a library, and each book has various details like the title, author, year of publication, and so on. The collection of these books is represented by the variable `books`. It's like a big, messy shelf where some books have tags that list their authors, while some might have forgotten to put their tags on (the authors are missing).\n",
       "\n",
       "Now, let's go through our magician's act step by step:\n",
       "\n",
       "1. **The Set Comprehension**: The part `{book.get(\"author\") for book in books if book.get(\"author\")}` is like a magical filtering tool. It examines each book on the shelf and says: \"Hey, if you have an author tag, I will collect that author's name!\" This creates a \"set\" of authors. Using a set helps us avoid duplicates – if two books are by the same author, we’ll only take one name, like a wise librarian who avoids the chaos of having the same note on multiple cards!\n",
       "\n",
       "2. **Yield from**: Now, the `yield from` part is like a little tour guide guiding you through a parade of names. Instead of giving you the whole jumble of author names at once, it offers them to you one by one. It’s like saying, \"Here’s the first author… and the next… and the next!\" This makes it much easier for you to interact with the data—perfect for when you don’t want to get overwhelmed!\n",
       "\n",
       "Putting it all together: This line of code is efficiently gathering a unique list of authors from the collection of books and then presents them to you one at a time, like a magician revealing each rabbit from a hat!\n",
       "\n",
       "So to summarize:\n",
       "- It collects authors from a list of books.\n",
       "- It ensures each author is listed only once (thanks to the magical set).\n",
       "- It presents them to you piece by piece using `yield`.\n",
       "\n",
       "Isn’t programming just like a good story? Full of twists, surprises, and a sprinkle of magic! If you have more questions or if there’s another enchanted code snippet you’re curious about, just let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "for chunk in stream:\n",
    "        if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:\n",
    "            # Get new content\n",
    "            new_content = chunk.choices[0].delta.content\n",
    "            # Add to running response\n",
    "            response += new_content\n",
    "            # Update the display with markdown formatting\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "            # Small delay for typewriter effect\n",
    "            import time\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "My curious learner!\n",
       "\n",
       "Let's break down this code together, shall we?\n",
       "\n",
       "Imagine you're at a library (not just any library, but one with a magical cataloging system). You have a list of books (`books`), and each book has some juicy information attached to it, like its author.\n",
       "\n",
       "The code uses a technique called **yield from** which is like a special kind of elevator that takes you from one place to another. In this case, it's like an elevator that takes us from the `books` list to a magical world where we can fetch book authors!\n",
       "\n",
       "Here's how it works:\n",
       "\n",
       "1. `{book.get(\"author\") for book in books if book.get(\"author\")}` is like a filter machine that selects only the books with author information.\n",
       "2. The `yield from` part is like the elevator (remember? . It takes us to this filtered list of books and says, \"Hey, I'm going to take you on a journey through these books and fetch their authors for you!\"\n",
       "\n",
       "So, what happens when we run this code?\n",
       "\n",
       "* It iterates over the `books` list.\n",
       "* For each book, it checks if the book has an author (by calling `book.get(\"author\")`). If it does, great! We get to ride the elevator!\n",
       "* The `yield from` part takes us on a journey through the filtered list of books and yields their authors one by one. It's like we're collecting all the authors' names and placing them in a basket for you.\n",
       "\n",
       "The result is an iterator that produces one author's name at a time, which you can then use as needed.\n",
       "\n",
       "To make it even more concrete, here's some sample Python code:\n",
       "```python\n",
       "class Book:\n",
       "    def __init__(self, title, author):\n",
       "        self.title = title\n",
       "        self.author = author\n",
       "\n",
       "books = [\n",
       "    Book(\"Book 1\", \"John Doe\"),\n",
       "    Book(\"Book 2\", None),\n",
       "    Book(\"Book 3\", \"Jane Smith\")\n",
       "]\n",
       "\n",
       "def get_author_names(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "for author in get_author_names(books):\n",
       "    print(author)  # Output: John Doe, Jane Smith\n",
       "```\n",
       "Voilà! You now know what this code does and how it works."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "stream = ollama.chat(\n",
    "            model=MODEL_OLLAMA,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"),display_id=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    if 'message' in chunk and 'content' in chunk['message']:\n",
    "        new_content = chunk['message']['content']\n",
    "        response += new_content\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "        time.sleep(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
