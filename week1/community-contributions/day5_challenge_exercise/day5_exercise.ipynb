{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e66023-eccf-46a9-8b70-7b21ede16ddd",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d21373-edbd-4432-a29d-db8e6c9c5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e4c15b-7ae8-43e9-839d-7cc49345be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb44166-1c65-42fc-9950-1960bc3cc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f5f1e1-5296-4631-9698-8645d4621a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "\n",
    "# Get the openai key\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key and openai_api_key.startswith('sk-proj-') and len(openai_api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "openai = OpenAI()\n",
    "# Get the ollama key using the llama model\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f07b33-76b9-42fa-9962-21f2a5796126",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a knowledgeable technical instructor who helps students understand \\\n",
    "complex concepts across a wide range of technical topics. Your expertise includes artificial]\\\n",
    "intelligence, machine learning, large language models (LLMs), and programming in languages \\\n",
    "such as Python, JavaScript, Java, and more. You also provide in-depth support for \\\n",
    "AI engineering questions and other advanced technical subjects.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330abeb7-7db2-4f23-9d19-dd698058a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a25551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to answer using selected model without duplicating logic\n",
    "\n",
    "def answer_question(question_text: str, model_choice: str):\n",
    "    if not question_text or not question_text.strip():\n",
    "        display(Markdown(\"**Please enter a question.**\"))\n",
    "        return\n",
    "\n",
    "    if model_choice == MODEL_GPT:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL_GPT,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question_text},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        response_text = \"\"\n",
    "        handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in stream:\n",
    "            response_text += chunk.choices[0].delta.content or \"\"\n",
    "            response_text = response_text.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(response_text), display_id=handle.display_id)\n",
    "        return\n",
    "\n",
    "    if model_choice == MODEL_LLAMA:\n",
    "        response = ollama_via_openai.chat.completions.create(\n",
    "            model=MODEL_LLAMA,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question_text},\n",
    "            ],\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        display(Markdown(result))\n",
    "        return\n",
    "\n",
    "    display(Markdown(f\"Unknown model: {model_choice}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd11ad48-91ec-4cdf-9c57-99a0451e7a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code you provided is a Python statement that uses the `yield from` expression in conjunction with a set comprehension. Let’s break it down step-by-step to understand what it does and why it’s written that way.\n",
       "\n",
       "### Breakdown of the Code\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   \n",
       "   - This part of the code is a set comprehension. It constructs a set containing authors' names.\n",
       "   - `books` is expected to be an iterable (like a list) of dictionaries, where each dictionary represents a book.\n",
       "   - `book.get(\"author\")` attempts to retrieve the value associated with the key \"author\" from each `book` dictionary.\n",
       "   - The `if book.get(\"author\")` condition filters out any books where the \"author\" key does not exist or has a value that evaluates to `False` (like `None` or an empty string). Only books with valid authors are included in the resulting set.\n",
       "\n",
       "2. **Yielding**:\n",
       "   python\n",
       "   yield from ...\n",
       "   \n",
       "   - The `yield from` expression is used within a generator function. It allows the generator to yield all values from another iterable (in this case, the set created by our set comprehension).\n",
       "   - When this statement is executed in the context of a generator function, it will yield all unique author names from the `books` collection.\n",
       "\n",
       "### Why Use This Code?\n",
       "\n",
       "1. **Efficiency**: Using a set comprehension guarantees that only unique authors are collected since sets do not allow duplicate elements. If you only wanted distinct authors, this is a concise and efficient way to do so.\n",
       "\n",
       "2. **Clarity**: By using `yield from`, the code clearly communicates that the generator will produce values from whatever is being yielded, in this case, the unique author names.\n",
       "\n",
       "3. **Generator Functionality**: This approach allows the code to be part of a larger generator function, which can provide the authors one-by-one on-demand (lazy evaluation), rather than all at once. This can be particularly useful if you're processing a large number of books and want to optimize memory usage.\n",
       "\n",
       "### Example Usage\n",
       "\n",
       "Here’s an example of how this might look in a full generator function:\n",
       "\n",
       "python\n",
       "def authors_generator(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Usage example\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 4\"}  # No author\n",
       "]\n",
       "\n",
       "for author in authors_generator(books):\n",
       "    print(author)\n",
       "\n",
       "\n",
       "### Output\n",
       "\n",
       "This would output:\n",
       "\n",
       "Author A\n",
       "Author B\n",
       "\n",
       "\n",
       "In summary, the code collects and yields unique author names from a collection of book dictionaries, helping you efficiently manage the data you work with."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "answer_question(question, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2527ae-0d75-4f15-a45f-92075e3059d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Decompiling the Code**\n",
       "\n",
       "This line of Python code uses a concept called \"context managers\" and \"generators.\" Let's break it down:\n",
       "\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "Here's what each part does:\n",
       "\n",
       "* `books` is an iterable (e.g., list, tuple, dictionary, set) containing objects with attributes or \"key-value pairs.\"\n",
       "* `{}` - This represents a dictionary comprehension.\n",
       "\t+ `.get()` is a method extracted from the dictionaries in the `books` iterable. It retrieves the value associated with the string key `\"author\"` from each dictionary, allowing it to return `None` if no such key exists (`book.get(\"author\")`)\n",
       "* `for book in books`: This loop iterates over each object (dictionary) in the `books` iterable.\n",
       "\t+ Inside this loop, `.get(\"author\")` is called for each dictionary, just like above. This extracts the author name as a string.\n",
       "* `yield from {...}`: This expression uses the `yield from` syntax, which introduces a \"generator\" - an object that defines how to generate a sequence of values.\n",
       "\n",
       "**How it works**\n",
       "\n",
       "1. The code creates a context manager for each dictionary in `books`.\n",
       "2. For each dictionary using `.get(\"author\")`, it captures the resulting value and stores it inside the `{...}` dictionary comprehension.\n",
       "3. When this expression is executed, it yields all the captured values (the author names) as if it were yielding from an iterator.\n",
       "\n",
       "**Equivalent Code**\n",
       "\n",
       "A more explicit equivalent of the code above would be:\n",
       "\n",
       "```python\n",
       "author_names = []\n",
       "for book in books:\n",
       "    author_name = book.get(\"author\")\n",
       "    if author_name:  # only if a key exists\n",
       "        author_names.append(author_name)\n",
       "for name in author_names:\n",
       "    yield name\n",
       "```\n",
       "\n",
       "However, this example does not utilize Python generators or comprehension, which is the purpose of the original line.\n",
       "\n",
       "**Use Cases and Performance Benefits**\n",
       "\n",
       "This kind of expression can be beneficial for several use cases:\n",
       "\n",
       "*   Generating large amounts of data: If you have a large dataset, a generator expression like `yield from {...}` may conserve more memory than a traditional list comprehension. The latter stores its entire output in RAM before using it.\n",
       "*   Handling infinite sequences: When dealing with potentially endless iterators (like those produced by certain types of algorithms), this syntax allows you to implement iterative processing without running out of memory.\n",
       "*   Creating iterators for data structures: This syntax helps reduce the necessity of manual iterator handling when working with collections or lists.\n",
       "\n",
       "In general, `yield from` expressions are often employed when tasks imply large datasets or sequential processing. They help reduce memory costs and improve overall code performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "answer_question(question, MODEL_LLAMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ef1575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3bd098ee1f42ebbc8b6924eb68e1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Model:', options=(('GPT', 'gpt-4o-mini'), ('LLaMA', 'llama3.2')), value='…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ipywidgets UI\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[(\"GPT\", MODEL_GPT), (\"LLaMA\", MODEL_LLAMA)],\n",
    "    value=MODEL_GPT,\n",
    "    description=\"Model:\",\n",
    ")\n",
    "\n",
    "question_area = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Ask your technical question here...\",\n",
    "    description=\"Question:\",\n",
    "    layout=widgets.Layout(width='100%', height='120px')\n",
    ")\n",
    "\n",
    "ask_button = widgets.Button(description=\"Ask\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def on_ask_clicked(_):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        answer_question(question_area.value, model_dropdown.value)\n",
    "\n",
    "\n",
    "ask_button.on_click(on_ask_clicked)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    model_dropdown,\n",
    "    question_area,\n",
    "    ask_button,\n",
    "    output,\n",
    "])\n",
    "\n",
    "ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2747739-ba64-4067-902f-c1acc0dbdaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
