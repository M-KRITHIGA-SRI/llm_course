{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "# import pdfplumber\n",
    "# import requests\n",
    "# from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "OLLAMA_API = \"http://localhost:11434/v1\"\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You are a helpful technical support assistant.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code you've provided is a Python expression that utilizes the `yield from` statement in conjunction with a set comprehension. Let's break it down step by step.\n",
       "\n",
       "### Components of the Code\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}`\n",
       "   - This part iterates over a collection called `books`, which is expected to be an iterable (like a list or a tuple) containing dictionaries (or objects) representing books.\n",
       "   - For each `book` in `books`, it attempts to retrieve the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
       "   - The `if book.get(\"author\")` condition ensures that only entries where the `\"author\"` key exists and has a truthy value (not `None`, `''`, `0`, etc.) are included in the resulting set.\n",
       "   - The result of this comprehension is a set of unique authors (as sets automatically handle duplicates).\n",
       "\n",
       "2. **`yield from`**:\n",
       "   - The `yield from` statement is used in a generator function to yield all values from an iterable. This means it will yield each element from the set created by the set comprehension one at a time.\n",
       "   - Using `yield from` helps in maintaining the state of the generator and simplifies the code when delegating to sub-generators or iterables.\n",
       "\n",
       "### What the Entire Code Does\n",
       "\n",
       "Putting it all together, this code snippet defines a part of a generator function that:\n",
       "- Extracts all unique authors from the `books` iterable.\n",
       "- Only includes authors that are present and have a truthy value.\n",
       "- Yields each unique author one by one whenever this generator function is called.\n",
       "\n",
       "### Example Scenario\n",
       "\n",
       "Suppose you have a list of books like this:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": None},\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 5\", \"author\": \"\"},\n",
       "]\n",
       "\n",
       "\n",
       "In this case, the set comprehension will create a set with `{\"Author A\", \"Author B\"}`. Then, when the generator function containing `yield from` runs, it will yield \"Author A\" first, followed by \"Author B\".\n",
       "\n",
       "### Summary\n",
       "\n",
       "- The code extracts unique author names from a collection of book dictionaries, skipping any entries where the author is missing or falsy.\n",
       "- It uses the generator pattern to yield each author sequentially, making it efficient in terms of memory and performance when dealing with potentially large datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def answer_openai(question, stream_response=False):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=stream_response\n",
    "    )\n",
    "    if stream_response:\n",
    "        result = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in response:\n",
    "            result += chunk.choices[0].delta.content or ''\n",
    "            result = result.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(result), display_id=display_handle.display_id)\n",
    "    else:\n",
    "        result = response.choices[0].message.content\n",
    "        display(Markdown(result))\n",
    "\n",
    "answer_openai(question,stream_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Generative Code Explanation**\n",
       "\n",
       "The given line of code is a generator expression used to iterate over a list of dictionaries (`books`) and extract the \"author\" field from each dictionary. Let's break it down:\n",
       "\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "**Step-by-Step Explanation**\n",
       "\n",
       "1. `{book.get(\"author\") for book in books}`: This is a dictionary comprehension that iterates over the `books` list, fetching the value associated with the key `\"author\"` from each dictionary.\n",
       "2. `if book.get(\"author\")`: This adds an additional condition to filter out any dictionaries where `\"author\"` doesn't exist.\n",
       "3. `yield from ...`: The `yield from` keyword is used in Python 3.3 and later versions. It allows a generator function to yield results from another generator or iterable.\n",
       "\n",
       "**What it does**\n",
       "\n",
       "This expression creates a new generator that yields the values of only those dictionaries (`book`) where `\"author\"` exists. However, this line cannot be part of a single line within Python code because `yield from` needs to be used as a top-level statement or inside a function for its full functionality.\n",
       "\n",
       "**Corrected Usage**\n",
       "\n",
       "If we wanted to achieve the same result in a more traditional generator expression:\n",
       "\n",
       "```python\n",
       "def books_authors(books):\n",
       "    for book in books:\n",
       "        if book.get(\"author\"):\n",
       "            yield book[\"author\"]\n",
       "\n",
       "# Example usage\n",
       "books = [\n",
       "    {\"author\": \"J.K. Rowling\", \"title\": \"Harry Potter\"},\n",
       "    {\"book_info\": \"Not an author-related field\"},\n",
       "    {\"author\": \"John Green\", \"publisher\": \"Penguin Press\"}\n",
       "]\n",
       "\n",
       "for author in books_authors(books):\n",
       "    print(author)\n",
       "```\n",
       "\n",
       "In this corrected code:\n",
       "\n",
       "- We define a generator function `books_authors` that yields the authors' names from dictionaries with existing `\"author\"` keys.\n",
       "- We create an instance of the generator and use it to extract authors from the list."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "# Use OPENAI API for consistency\n",
    "\n",
    "def answer_ollama(question, stream_response=False):\n",
    "    ollama_via_openai = OpenAI(base_url=OLLAMA_API, api_key='ollama')\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=stream_response\n",
    "    )\n",
    "    if stream_response:\n",
    "        result = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in response:\n",
    "            result += chunk.choices[0].delta.content or ''\n",
    "            result = result.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(result), display_id=display_handle.display_id)\n",
    "    else:\n",
    "        result = response.choices[0].message.content\n",
    "        display(Markdown(result))\n",
    "\n",
    "answer_ollama(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70754c-12c4-438b-bacd-e9e244aec7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324722c-3359-48a6-a930-f0cf91d3b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
