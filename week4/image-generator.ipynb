{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "from diffusers import DiffusionPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (0.33.1)\n",
      "Requirement already satisfied: transformers in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: peft in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (0.15.2)\n",
      "Requirement already satisfied: importlib-metadata in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (0.30.2)\n",
      "Requirement already satisfied: numpy in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (0.5.3)\n",
      "Requirement already satisfied: Pillow in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from diffusers) (11.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: psutil in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from sympy!=1.13.2,>=1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->diffusers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->diffusers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ulysses/anaconda3/envs/llms/lib/python3.11/site-packages (from requests->diffusers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install diffusers transformers torch accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-23 19:25:54,743 - WARNING - huggingface_hub._login - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-05-23 19:25:54,744 - INFO - __main__ - Successfully logged into Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
    "logger = logging.getLogger(__name__) # Create a logger for this module\n",
    "\n",
    "# --- Authentication\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    logger.warning(\"HF_TOKEN environment variable not found. Some operations might fail.\")\n",
    "else:\n",
    "    try:\n",
    "        login(hf_token, add_to_git_credential=True)\n",
    "        logger.info(\"Successfully logged into Hugging Face Hub.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to log into Hugging Face Hub: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc5e6c100e2443bb63f7a3396007a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eddd429b6f455dab0f41c25ec67a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655204c618cc4056b951e6b5f8448050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline device: mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7dd9b2655e48d2ab2dd41e1118a796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 20:51:27,656 - INFO - __main__ - Image created successfully\n",
      "2025-05-23 20:51:28,193 - INFO - __main__ - Memory cleared successfully\n"
     ]
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\"\n",
    "    )\n",
    "pipe = pipe.to(\"mps\")\n",
    "pipe.load_lora_weights(\"multimodalart/isometric-skeumorphic-3d-bnb\")\n",
    "\n",
    "#prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n",
    "#prompt = \"Home with fusion architecture of vietnamese and mexican styles, warm colors, detailed, 4k\"\n",
    "#prompt = \"Ragnarok online female inquisitor, fighting stance, rampage blast, white hair, wearing a Duneyrr Helm, detailed, 4k\"\n",
    "\n",
    "# Isometric Prompt when using weight ~ Comment it on when not using the model\n",
    "#prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, RBNBICN, icon, white background, isometric perspective\"\n",
    "#prompt = \"Home with fusion architecture of vietnamese and mexican styles, warm colors, detailed, 4k, RBNBICN, icon, white background, isometric perspective\"\n",
    "#prompt = \"Ragnarok online female inquisitor, fighting stance, rampage blast, detailed, 4k, RBNBICN, icon, white background, isometric perspective\"\n",
    "prompt = \"Ragnarok online Prontera City, detailed, 4k, RBNBICN, icon, white background, isometric perspective\"\n",
    "\n",
    "# Add some debug prints to check device placement\n",
    "print(f\"Pipeline device: {pipe.device}\")\n",
    "\n",
    "def clear_memory():\n",
    "    # Clear MPS cache\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    # Force garbage collection\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    # Log memory status\n",
    "    logger.info(\"Memory cleared successfully\")\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    #height=1024,\n",
    "    #width=1024,\n",
    "    # guidance_scale=3.5,\n",
    "    # num_inference_steps=50,\n",
    "    # max_sequence_length=512,\n",
    "    # generator=torch.Generator(\"mps\").manual_seed(0)  # Changed from \"cpu\" to \"mps\"\n",
    ").images[0]\n",
    "image.save(\"prontera-city-isometric.png\")\n",
    "logger.info(\"Image created successfully\")\n",
    "clear_memory() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
